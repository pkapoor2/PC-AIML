{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXs-jbe_PRKk"
   },
   "source": [
    "\n",
    "In this example, we build and train a deep learning model using the FashionMNIST dataset, which consists of 28x28 grayscale images of 10 different clothing items. The model, a convolutional neural network (CNN), is trained to classify these images into their respective categories, leveraging PyTorch for the implementation and employing techniques such as normalization and Adam optimization to enhance performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iO5slsKdOT7S"
   },
   "source": [
    "## Steps to be followed:\n",
    "\n",
    "1. Import necessary libraries\n",
    "2. Data Preprocessing Setup\n",
    "3. Load Datasets\n",
    "4. Initialize DataLoaders\n",
    "5. Define the CNN Model\n",
    "6. Set Up Loss Function and Optimizer\n",
    "7. Training the Model\n",
    "8. Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4mEkTO1JYMj"
   },
   "source": [
    "### Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 12709,
     "status": "ok",
     "timestamp": 1719131392079,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "dbhIGhSZHPD-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\prate\\miniconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\prate\\miniconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\prate\\miniconda3\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\prate\\miniconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\prate\\miniconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\prate\\miniconda3\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\prate\\miniconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\prate\\miniconda3\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\prate\\miniconda3\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\prate\\miniconda3\\lib\\site-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\prate\\miniconda3\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prate\\miniconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prate\\miniconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exj9jhx6JfOf"
   },
   "source": [
    "### Step 2:  Data Preprocessing Setup\n",
    "- Define transformations for the input data:\n",
    "     - `ToTensor():` Converts image data from PIL format or NumPy arrays to PyTorch tensors.\n",
    "     - `Normalize((0.5,), (0.5,)):` Normalizes tensor images using mean = 0.5 and std = 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 451,
     "status": "ok",
     "timestamp": 1719131395723,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "sbFO3iXEHQI3"
   },
   "outputs": [],
   "source": [
    "# Data preprocessing: normalization\n",
    "transform_nm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w5vNdd0KqpK"
   },
   "source": [
    "### Step 3: Load Datasets\n",
    "- **Train Dataset:** Load FashionMNIST training data, applying the defined transformations.\n",
    "- **Test Dataset:** Load FashionMNIST test data similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5159,
     "status": "ok",
     "timestamp": 1719131413026,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "4WrAyiPrKkOf",
    "outputId": "d30bfc3e-7233-431b-c41d-92da6f172ffe"
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "train_dataset_nm = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform_nm)\n",
    "test_dataset_nm = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIfqZRn3K7cF"
   },
   "source": [
    "### Step 4: Initialize DataLoaders\n",
    "- `Training DataLoader:` Batches, shuffles, and prepares training data for processing in the model.\n",
    "- `Testing DataLoader:` Batches and prepares test data for evaluation (shuffling is not necessary for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1719131419999,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "JZaKpv8_K5M4",
    "outputId": "d2713b1f-0018-4d5b-bf1b-d0317cdb703b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 60000 samples\n",
      "Testing data: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "train_loader_nm = torch.utils.data.DataLoader(train_dataset_nm, batch_size=32, shuffle=True)\n",
    "test_loader_nm = torch.utils.data.DataLoader(test_dataset_nm, batch_size=32, shuffle=False)\n",
    "\n",
    "# Printing the shape of the datasets\n",
    "print(f'Training data: {len(train_dataset_nm)} samples')\n",
    "print(f'Testing data: {len(test_dataset_nm)} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P76J4B0LXcN"
   },
   "source": [
    "### Step 5: Define the CNN Model\n",
    "- **Model Class Initialization:** Set up the neural network structure with layers defined in the `__init__` method.\n",
    "- **Layers:** Include one convolutional layer, one pooling layer, and two fully connected layers.\n",
    "- **Data Flow through Layers:** Define how data moves through the model using the forward method, incorporating activations (ReLU) and pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1719131442463,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "M7B9NI0GHW6N"
   },
   "outputs": [],
   "source": [
    "# Define a convolutional neural network for classifying FashionMNIST dataset images\n",
    "class FashionMNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionMNISTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc_hidden = nn.Linear(13*13*32, 100)\n",
    "        self.fc_output = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 13*13*32)\n",
    "        x = self.fc_hidden(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc_output(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrV40jK5L3ky"
   },
   "source": [
    "### Step 6: Set Up Loss Function and Optimizer\n",
    "\n",
    "- **CrossEntropyLoss:** Used for multi-class classification tasks.\n",
    "- **Adam Optimizer:** A method for stochastic optimization with a set learning rate of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 405,
     "status": "ok",
     "timestamp": 1719131453354,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "lYQXFP23HcoL"
   },
   "outputs": [],
   "source": [
    "model = FashionMNISTCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "568tU_i9MZ5D"
   },
   "source": [
    "### Step 7: Training the Model and saving it at each epoch\n",
    "\n",
    "- **Epoch Iteration:** Loop through the dataset multiple times (epochs).\n",
    "- **Batch Processing:** For each batch in the DataLoader, perform forward pass, loss calculation, backpropagation, and parameter update.\n",
    "- **Save Model State:** Save the model after training to reuse it later without needing to retrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 498399,
     "status": "ok",
     "timestamp": 1719132041602,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "hngY_lgtf8_I",
    "outputId": "27ecbc77-994c-4cdc-9757-92d7ef1776a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.39879183058540024, Train Accuracy: 85.74666666666667%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 2/10, Loss: 0.26612817190289495, Train Accuracy: 90.37333333333333%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 3/10, Loss: 0.2216284805228313, Train Accuracy: 91.945%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 4/10, Loss: 0.1883942069063584, Train Accuracy: 93.05%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 5/10, Loss: 0.1620183053433895, Train Accuracy: 94.01166666666667%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 6/10, Loss: 0.13680088447729746, Train Accuracy: 94.945%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 7/10, Loss: 0.1175761468090117, Train Accuracy: 95.71%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 8/10, Loss: 0.09986156567347547, Train Accuracy: 96.26666666666667%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 9/10, Loss: 0.08623724563966195, Train Accuracy: 96.845%\n",
      "Model saved to ./mnist_model.pth\n",
      "Epoch 10/10, Loss: 0.074453572653234, Train Accuracy: 97.26166666666667%\n",
      "Model saved to ./mnist_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Training the model for 10 epochs\n",
    "# Define the path for saving the model\n",
    "model_path = './mnist_model.pth'\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images_nm, labels_nm in train_loader_nm:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs_nm = model(images_nm)\n",
    "        loss = criterion(outputs_nm, labels_nm)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted_train = torch.max(outputs_nm.data, 1)\n",
    "        total_train += labels_nm.size(0)\n",
    "        correct_train += (predicted_train == labels_nm).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader_nm)}, Train Accuracy: {train_accuracy}%\")\n",
    "\n",
    "    # Save the model at the end of each epoch\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmCNF_mxMu5X"
   },
   "source": [
    "### Step 8:  Evaluate the Model\n",
    "- **Switch to Evaluation Mode:** Ensure the model is in eval mode to disable dropout or batch norm effects during testing.\n",
    "- **Accuracy Calculation:** Compare the modelâ€™s output to the true labels, calculate overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5505,
     "status": "ok",
     "timestamp": 1719132176590,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "zFubvmv-Hfmx",
    "outputId": "847acb15-ad13-43cb-9aa5-730f46430fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 91.45%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images_nm, labels_nm in test_loader_nm:\n",
    "        outputs_nm = model(images_nm)\n",
    "        _, predicted = torch.max(outputs_nm.data, 1)\n",
    "        total += labels_nm.size(0)\n",
    "        correct += (predicted == labels_nm).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Model accuracy on test set: {accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
