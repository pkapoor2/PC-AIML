{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0YnaxeLGCY4"
   },
   "source": [
    "# __Assisted Practice: Training Deep Neural Networks on TensorFlow__\n",
    "Building Deep Neural Networks on TensorFlow refers to the process of designing and constructing neural network models using the TensorFlow framework. This involves defining the architecture of the neural network, selecting appropriate layers and activation functions, specifying the optimization algorithm, and training the model using data.\n",
    "\n",
    "Let's understand how to build and train a neural network using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saSuWUrGGPIa"
   },
   "source": [
    "\n",
    "\n",
    "## Steps to be followed:\n",
    "1. Import the required libraries\n",
    "2. Load and inspect the data\n",
    "3. Build the model\n",
    "4. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkfqjK31CXXV"
   },
   "source": [
    "### Step 1: Import the required libraries\n",
    "\n",
    "- Import Pandas and NumPy packages.\n",
    "- Import the TensorFlow package, which is used for text-based applications, image recognition, voice search, and many more.\n",
    "- Import the Python package cv2, which is used for computer vision and image processing.\n",
    "- Import the Python package matplotlib, which sets the padding between and around the subplots as well as the figure size.\n",
    "- Import necessary libraries and modules for building a deep learning model using TensorFlow. It includes modules for convolutional and pooling layers, dropout, flattening, and dense layers.\n",
    "- Import other libraries for data manipulation, visualization, and image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.17.0 scikeras==0.13.0 keras==3.2.0\n",
    "# Got CUDA?\n",
    "#uv --native-tls pip install \"tensorflow[and-cuda]\"\n",
    "# or conda, or just pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable oneDNN optimizations to avoid potential minor numerical differences caused by floating-point round-off errors.\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 17519,
     "status": "ok",
     "timestamp": 1719080146574,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "Qz6slja9GCY8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 20:11:47.455697: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-04 20:11:47.528131: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-04 20:11:47.550581: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-04 20:11:47.680537: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-04 20:11:49.013895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow and required layers for building the model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Import other necessary libraries for data manipulation, visualization, and image processing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import IPython\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Is built with CUDA:  True\n",
      "Is GPU available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version:  2.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757034711.832911   13776 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1757034712.130684   13776 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1757034712.130745   13776 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Is built with CUDA: \", tf.test.is_built_with_cuda())\n",
    "print(\"Is GPU available: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"TensorFlow version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision policy: <FloatDTypePolicy \"float32\">\n"
     ]
    }
   ],
   "source": [
    "# [gpu-setup] TensorFlow GPU diagnostics, memory growth, dtype policy, and warm-up helpers\n",
    "\n",
    "# Enable memory growth to avoid allocator / handle issues\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except Exception as e:\n",
    "        print(\"set_memory_growth failed:\", e)\n",
    "\n",
    "# Force plain float32 everywhere (avoid mixed-precision surprises)\n",
    "try:\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy(\"float32\")\n",
    "    print(\"Mixed precision policy:\", mixed_precision.global_policy())\n",
    "except Exception as e:\n",
    "    print(\"Mixed precision policy not set:\", e)\n",
    "\n",
    "# Warm-up helper function\n",
    "def gpu_warmup(model, feature_dim: int):\n",
    "    dummy = np.zeros((1, feature_dim), dtype=np.float32)\n",
    "    _ = model(dummy, training=False)\n",
    "    print(\"GPU warm-up done for input dim\", feature_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Force CPU usage if needed\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757034712.167201   13776 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1757034712.167316   13776 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1757034712.167336   13776 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1757034712.388999   13776 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1757034712.389225   13776 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-04 20:11:52.389242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1757034712.389460   13776 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-09-04 20:11:52.389623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13717 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Configure GPU memory growth to avoid CUDA errors\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYhwB5u8GCY-"
   },
   "source": [
    "### Step 2: Load and inspect the data\n",
    "\n",
    "\n",
    "- Load the California Housing dataset from **`fetch_california_housing`**.\n",
    "- Split the dataset into two sets: the training set **train_features** and **train_labels** and the testing set **test_features** and **test_labels**.\n",
    "- The testing set is used to evaluate the trained model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1820,
     "status": "ok",
     "timestamp": 1719080148369,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "KaFEYTKKGCZA"
   },
   "outputs": [],
   "source": [
    "# Load the California Housing dataset from sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "data = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "data['target'] = housing.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data[housing.feature_names], data['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1719080178457,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "duafEb2UGCZA",
    "outputId": "efbc245b-d46b-4c99-f3ac-908cd11fab28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.326196    0.34849025 -0.17491646 ...  0.05137609 -1.3728112\n",
      "   1.27258656]\n",
      " [-0.03584338  1.61811813 -0.40283542 ... -0.11736222 -0.87669601\n",
      "   0.70916212]\n",
      " [ 0.14470145 -1.95271028  0.08821601 ... -0.03227969 -0.46014647\n",
      "  -0.44760309]\n",
      " ...\n",
      " [-0.49697313  0.58654547 -0.60675918 ...  0.02030568 -0.75500738\n",
      "   0.59946887]\n",
      " [ 0.96545045 -1.07984112  0.40217517 ...  0.00707608  0.90651045\n",
      "  -1.18553953]\n",
      " [-0.68544764  1.85617335 -0.85144571 ... -0.08535429  0.99543676\n",
      "  -1.41489815]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_data)\n",
    "test_features = scaler.transform(test_data)\n",
    "\n",
    "# Print the standardized training features\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_ZxZUEeF8iN"
   },
   "source": [
    " __Observation:__\n",
    "\n",
    "\n",
    "- Here, we can see a few datasets from train dataset.\n",
    "- The given array represents a multi-dimensional array containing numerical values.\n",
    "- Each row in the array corresponds to a set of features or data points, while each column represents a specific feature or variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5fZchhYFbBZ"
   },
   "source": [
    "### Step 3: Build the Model\n",
    "Building the neural network requires:\n",
    "- Configuring the layers of the model and compiling the model.\n",
    "- Stacking a few layers together using **keras.Sequential**.\n",
    "- Configuring the loss function, optimizer, and metrics to monitor.\n",
    "These are added during the model's compile step.\n",
    "\n",
    "Why MLP Regressor?\n",
    "- MLP = Multi-layer Percpetron, a fully connected feed-forward neural network, ideal for tabular data\n",
    "- Regressor: the output is a single continuous value (not a probability distribution)\n",
    "- The target variable is continuous, which is a regression problem\n",
    "- Input variables are vector features\n",
    "\n",
    "Terminologies:\n",
    "- The **Loss** function measures how accurate the model is during training; we want to minimize this with the optimizer.\n",
    "- One must **Optimize** how the model is updated based on the data it sees and its loss function.\n",
    "- **Metrics** are used to monitor the training and testing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1719080417959,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "kg01bCMMGCZC"
   },
   "outputs": [],
   "source": [
    "# Function to build the neural network model\n",
    "def build_model(input_dim: int):\n",
    "    inputs = keras.Input(shape=(input_dim,), dtype=\"float32\", name=\"features\")\n",
    "    # Hidden layer with 20 neurons and ReLU activation (20 seems like a good balance between underfitting and overfitting)\n",
    "    x = layers.Dense(20, activation=\"relu\")(inputs)\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"mlp_regressor\")\n",
    "    # Compile the model with Adam optimizer and Mean Absolute Error loss function\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=\"mae\",\n",
    "        metrics=[\"mean_absolute_error\"]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkM_Ixa_GCZD"
   },
   "source": [
    "### Step 4: Train the model\n",
    "Training the neural network model requires the following steps:\n",
    "\n",
    "\n",
    "- Define a custom callback class **PrintDot**, which prints a dot for every epoch during training.\n",
    "\n",
    "  `PrintDot` is a custom callback class in Keras that is used to provide visual feedback during the training process of a neural network. It prints a dot (.) for every epoch completed, and it prints a new line every 100 epochs. This helps in monitoring the progress of the training process in a simple and visual way without overwhelming the console with too much information.\n",
    "\n",
    "- Create an instance of the model using the **build_model** function.\n",
    "\n",
    "- Create an instance of EarlyStopping callback, which monitors the validation loss and stops training if it doesn't improve after a certain number of epochs (specified by patience).\n",
    "\n",
    "- Train the model using the training features and labels. It runs for 200 epochs, with a validation split of 0.1 (10% of the training data used for validation). The callbacks parameter includes **early_stop** and **PrintDot** callbacks.\n",
    "\n",
    "- Create a Pandas **DataFrame hist** from the history object returned by the model.fit method. It contains the recorded training and validation metrics.\n",
    "\n",
    "- Extract the last value of the validation mean absolute error (MAE) from the hist DataFrame and assign it to the variable mae_final.\n",
    "\n",
    "- Print the final MAE on the validation set, rounded to three decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why MAE instead of MSE?\n",
    "\n",
    "  MAE (Mean Absolute Error):\n",
    "  - Less sensitive to outliers\n",
    "  - All errors weighted equally\n",
    "  - Easier to interpret (same units as target)\n",
    "  - More robust for datasets with extreme values\n",
    "\n",
    "  MSE (Mean Squared Error):\n",
    "  - Heavily penalizes large errors (squared penalty)\n",
    "  - More sensitive to outliers\n",
    "  - Mathematical properties better for optimization\n",
    "  - Standard choice for many regression tasks\n",
    "\n",
    "  For the California Housing dataset, MAE is often preferred because:\n",
    "  1. Housing prices have natural outliers (luxury homes)\n",
    "  2. MAE gives you interpretable error in dollars\n",
    "  3. You might care equally about all prediction errors, not just large ones\n",
    "\n",
    "  MSE would amplify the impact of expensive homes, potentially making the model focus too much on\n",
    "  getting those predictions right while ignoring typical homes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 167910,
     "status": "ok",
     "timestamp": 1719081211819,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "8WocKoO9GCZE",
    "outputId": "8fe50642-db86-4166-af8b-5c25d136d3ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU warm-up done for input dim 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757034715.771949   13869 service.cc:146] XLA service 0x7f756c009250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1757034715.772082   13869 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Laptop GPU, Compute Capability 8.6\n",
      "2025-09-04 20:11:55.808544: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-04 20:11:55.912997: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "I0000 00:00:1757034716.320273   13869 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "...................................................................................................."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_regressor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mlp_regressor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ features (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ features (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m180\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">605</span> (2.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m605\u001b[0m (2.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> (804.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201\u001b[0m (804.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> (1.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m404\u001b[0m (1.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Final Mean Absolute Error on validation set: 0.377\n"
     ]
    }
   ],
   "source": [
    "# Custom callback class to print a dot for every epoch\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('')\n",
    "        print('.', end='')\n",
    "\n",
    "# Build the model using the build_model function\n",
    "model = build_model(input_dim=train_features.shape[1])\n",
    "\n",
    "# Warm up the GPU\n",
    "gpu_warmup(model, train_features.shape[1])\n",
    "\n",
    "# Early stopping callback to stop training if validation loss doesn't improve for 20 epochs, good balance to avoid overfitting\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# Train the model with training data, using 10% of the data for validation\n",
    "history = model.fit(train_features, train_labels, epochs=200, verbose=0, validation_split=0.1,\n",
    "                    callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "# Create a Pandas DataFrame from the training history\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "# Extract the final mean absolute error from the validation set\n",
    "mae_final = float(hist['val_mean_absolute_error'].iloc[-1])\n",
    "\n",
    "print(model.summary())\n",
    "print()\n",
    "print('Final Mean Absolute Error on validation set: {}'.format(round(mae_final, 3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r7uOD6jLYx-"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "As shown, the final mean absolute error on the validation set is 0.38."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZeUxYF9HML2"
   },
   "source": [
    "\n",
    "- Evaluate the model's performance on the normalized test features and prints the mean absolute error (MAE) on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1719081448465,
     "user": {
      "displayName": "Aleena Raj",
      "userId": "16635257578699511263"
     },
     "user_tz": -330
    },
    "id": "LQbYz8kMGCZE",
    "outputId": "9a7a0516-b961-4230-bf31-2e254b8cdd84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3653 - mean_absolute_error: 0.3653\n",
      "Mean Absolute Error on test set: 0.366\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance on the test set\n",
    "mae, _ = model.evaluate(test_features, test_labels)\n",
    "print('Mean Absolute Error on test set: {}'.format(round(mae, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCrX2XQzL1x3"
   },
   "source": [
    "**Observation:**\n",
    "\n",
    "The output indicates the following:\n",
    "\n",
    "- The evaluation was performed on the `test_features` and `test_labels`.\n",
    "- The mean absolute error, when rounded, is 0.37.\n",
    "- The fact that our test MAE is lower than our validation MAE suggests that the model generalized well to unseen data, with no overfitting.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "teach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
