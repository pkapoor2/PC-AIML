{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 2: Approach Overview\n",
    "## Preserving Heritage with AI\n",
    "\n",
    "This notebook provides a high-level overview of how to approach the Capstone 2 project. It outlines the key steps, decisions, and methodologies without providing complete code solutions.\n",
    "\n",
    "**Goal:** Help you understand the problem-solving framework and key considerations for each part of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This capstone consists of two distinct machine learning tasks:\n",
    "\n",
    "1. **Part 1: Historical Structure Classification** - Build a deep learning model to classify 11 different types of historical structures from images\n",
    "2. **Part 2: Tourism Recommendation System** - Create a collaborative filtering system to recommend tourist destinations based on user ratings\n",
    "\n",
    "Both parts demonstrate practical AI applications in cultural heritage preservation and tourism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Historical Structure Classification\n",
    "\n",
    "### Overview\n",
    "Build a deep learning image classification model to identify 11 categories of historical structures (e.g., temples, palaces, forts, monuments).\n",
    "\n",
    "**Target Performance:** 75-85% validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Data Exploration Strategy\n",
    "\n",
    "**Initial Steps:**\n",
    "- Extract the dataset from the nested ZIP file structure\n",
    "- Understand the directory organization (train/test splits, class folders)\n",
    "- Count images per class to check for imbalance\n",
    "\n",
    "**Visual Exploration:**\n",
    "- Display 8-10 sample images from each class\n",
    "  - Helps you understand what each category looks like\n",
    "  - Identify image quality issues or mislabeled data\n",
    "  - Get a sense of within-class variation\n",
    "\n",
    "**Class Distribution Analysis:**\n",
    "- Create bar charts showing number of images per class\n",
    "- Check for significant class imbalance\n",
    "  - Balanced dataset: roughly equal images per class\n",
    "  - Imbalanced dataset: may need special handling (weighted loss, oversampling)\n",
    "\n",
    "**Key Questions to Answer:**\n",
    "- How many total images do you have?\n",
    "- Are all 11 classes represented?\n",
    "- Do some classes look more difficult to distinguish?\n",
    "- What's the image quality and resolution?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### 1.1.1 ⚠️ Handling Corrupted Images - A Real-World Challenge\n\n**Important Real-World Issue:**\n\nThis dataset contains some **corrupted or truncated image files**. This is extremely common in real-world datasets and an important skill to handle!\n\n**What are corrupted images?**\n- Files that are incomplete or damaged\n- Images that failed to download completely\n- Files with corrupted headers or data\n- Can cause your training to crash with errors like:\n  - `OSError: image file is truncated`\n  - `UnidentifiedImageError: cannot identify image file`\n  - `PIL.Image.DecompressionBombError`\n\n**Two Approaches to Handle This:**\n\n**Approach 1: Graceful Loading (Recommended for this project)**\n- Configure PIL to load truncated images anyway\n- Add this at the start of your notebook:\n  ```python\n  from PIL import ImageFile\n  ImageFile.LOAD_TRUNCATED_IMAGES = True\n  ```\n- **Pros:** Simple, one line of code, keeps all data\n- **Cons:** Corrupted images may still affect model quality\n- **When to use:** When corruption is minor and you want maximum data\n\n**Approach 2: Identify and Remove Corrupted Files**\n- Scan through all images before training\n- Try to open each image\n- Remove files that can't be loaded\n- **Pros:** Clean dataset, no training interruptions\n- **Cons:** Lose some data, takes time to scan\n- **When to use:** When you need guaranteed data quality\n\n**How to Scan and Remove Corrupted Images:**\n\n```python\nfrom PIL import Image, UnidentifiedImageError\nimport os\n\ndef find_corrupted_images(directory):\n    corrupted_files = []\n    \n    for root, dirs, files in os.walk(directory):\n        for filename in files:\n            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n                filepath = os.path.join(root, filename)\n                try:\n                    # Try to open and verify\n                    img = Image.open(filepath)\n                    img.verify()\n                    img.close()\n                    # Re-open and load fully\n                    img = Image.open(filepath)\n                    img.load()\n                    img.close()\n                except Exception as e:\n                    print(f\"Corrupted: {filepath}\")\n                    corrupted_files.append(filepath)\n    \n    return corrupted_files\n\n# Option: Remove them\n# for filepath in corrupted_files:\n#     os.remove(filepath)\n```\n\n**Best Practice for This Project:**\n\n1. **Start with Approach 1** (graceful loading)\n   - Add `ImageFile.LOAD_TRUNCATED_IMAGES = True`\n   - See if training works smoothly\n\n2. **If you get persistent errors:**\n   - Switch to Approach 2\n   - Scan and remove corrupted files\n   - Document how many files were removed\n\n3. **Always document your choice:**\n   - Note in your notebook which approach you used\n   - Report how many corrupted images (if you scanned)\n   - This shows awareness of real-world data quality issues\n\n**Why This Matters:**\n\n- **Real-world datasets are messy!** This is normal\n- **Production systems must handle this** - you can't just crash\n- **Shows data engineering maturity** - good practitioners expect and handle data issues\n- **Important for your portfolio** - employers value students who handle real problems\n\n**Expected Impact:**\n- Typically affects <1-5% of images in this dataset\n- Minimal impact on final model accuracy\n- But critical for smooth training process!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Data Preprocessing and Augmentation\n",
    "\n",
    "**Core Preprocessing (Required for ALL images):**\n",
    "- **Resize:** All images to consistent size (e.g., 224×224 for ResNet)\n",
    "- **Normalize:** Use ImageNet statistics (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "  - This is CRITICAL when using pre-trained models\n",
    "  - Pre-trained models expect inputs normalized this way\n",
    "\n",
    "**Data Augmentation (Training data only):**\n",
    "\n",
    "Why augment?\n",
    "- Artificially increase dataset diversity\n",
    "- Help model generalize better\n",
    "- Reduce overfitting\n",
    "- Expected improvement: 5-10% accuracy\n",
    "\n",
    "**Recommended augmentation techniques:**\n",
    "1. **Random Horizontal Flip** (50% probability)\n",
    "   - Buildings can appear from left or right\n",
    "   - DON'T use vertical flip (buildings don't appear upside-down)\n",
    "\n",
    "2. **Random Rotation** (±10 to ±15 degrees)\n",
    "   - Simulates different camera angles\n",
    "   - Don't rotate too much (buildings won't be sideways)\n",
    "\n",
    "3. **Color Jitter**\n",
    "   - Brightness, contrast, saturation, hue variations\n",
    "   - Simulates different lighting conditions and cameras\n",
    "\n",
    "4. **Random Affine** (optional)\n",
    "   - Small translations (±10%)\n",
    "   - Simulates different framing\n",
    "\n",
    "5. **Random Perspective** (optional)\n",
    "   - Small perspective distortions\n",
    "   - Simulates different viewing angles\n",
    "\n",
    "**Important Considerations:**\n",
    "- Apply augmentation ONLY to training data\n",
    "- Validation/test data should only be resized and normalized\n",
    "- Don't augment so heavily that you lose important features\n",
    "- Augmentation happens on-the-fly during training (different each epoch)\n",
    "\n",
    "**Experimental Approach:**\n",
    "You should train TWO models:\n",
    "1. Baseline (no augmentation) - to establish performance floor\n",
    "2. With augmentation - to measure improvement\n",
    "This comparison helps you understand augmentation's impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Data Loading\n",
    "\n",
    "**PyTorch DataLoader Configuration:**\n",
    "\n",
    "**Batch Size:**\n",
    "- Typical: 16-32 for image classification\n",
    "- Larger batches: More stable gradients, faster training (if GPU memory allows)\n",
    "- Smaller batches: More gradient noise (can help generalization), less memory\n",
    "- Adjust based on your GPU memory availability\n",
    "\n",
    "**Other Settings:**\n",
    "- `shuffle=True` for training data (randomize order each epoch)\n",
    "- `shuffle=False` for validation data (consistent evaluation)\n",
    "- `num_workers`: 2-4 for faster data loading (parallel processing)\n",
    "- `pin_memory=True` if using GPU (faster data transfer)\n",
    "\n",
    "**Train/Validation Split:**\n",
    "- If you have a separate test set: Use it as-is\n",
    "- If not: Split training data ~80/20 or 85/15 for train/validation\n",
    "- Keep validation set for hyperparameter tuning\n",
    "- Test set for final evaluation only\n",
    "\n",
    "**Visualization:**\n",
    "- Display a batch of training images to verify:\n",
    "  - Augmentation is working\n",
    "  - Images are properly normalized\n",
    "  - Labels are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Model Architecture Selection\n",
    "\n",
    "**Recommended Approach: Transfer Learning with ResNet50**\n",
    "\n",
    "**Why Transfer Learning?**\n",
    "- You likely have a relatively small dataset (few thousand images)\n",
    "- Training from scratch requires hundreds of thousands of images\n",
    "- Pre-trained models already learned useful features (edges, textures, shapes)\n",
    "- Dramatically reduces training time (hours → minutes)\n",
    "- Better performance with less data\n",
    "\n",
    "**Why ResNet50?**\n",
    "- **Proven architecture:** ResNet (Residual Networks) is industry-standard\n",
    "- **Good capacity:** 50 layers deep, can learn complex patterns\n",
    "- **Not too heavy:** Efficient enough for training without excessive resources\n",
    "- **Pre-trained weights available:** Trained on ImageNet (1.2M images, 1000 classes)\n",
    "- **Alternative options:** ResNet18 (lighter), ResNet101 (heavier), VGG16, EfficientNet\n",
    "\n",
    "**Transfer Learning Strategy:**\n",
    "\n",
    "**Option 1: Feature Extraction (Recommended for this project)**\n",
    "- Freeze ALL convolutional layers\n",
    "- Only train the custom classifier head\n",
    "- Fastest training, works well for small datasets\n",
    "- Prevents overfitting\n",
    "\n",
    "**Option 2: Fine-Tuning (Advanced)**\n",
    "- Freeze early layers\n",
    "- Unfreeze later layers\n",
    "- Train with very small learning rate\n",
    "- Better performance but risk of overfitting\n",
    "\n",
    "**Custom Classifier Design:**\n",
    "\n",
    "Replace ResNet's final layer with a custom head:\n",
    "- Input: 2048 features (from ResNet50)\n",
    "- Hidden layer 1: Dense(512) → ReLU → BatchNorm → Dropout(0.5)\n",
    "- Hidden layer 2: Dense(256) → ReLU → Dropout(0.3)\n",
    "- Output: Dense(11) → Softmax (11 classes)\n",
    "\n",
    "**Why this architecture?**\n",
    "- **Two hidden layers:** Gradually reduce dimensions (2048 → 512 → 256 → 11)\n",
    "- **BatchNorm:** Stabilizes training, allows higher learning rates\n",
    "- **Dropout:** Prevents overfitting by randomly dropping neurons during training\n",
    "  - Higher dropout (0.5) early, lower (0.3) later\n",
    "- **ReLU activation:** Standard choice, prevents vanishing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Training Configuration\n",
    "\n",
    "**Loss Function:**\n",
    "- **CrossEntropyLoss** for multi-class classification\n",
    "- Combines LogSoftmax and NLLLoss\n",
    "- Standard choice for this type of problem\n",
    "\n",
    "**Optimizer:**\n",
    "- **Adam** is recommended\n",
    "  - Adaptive learning rate for each parameter\n",
    "  - Handles sparse gradients well\n",
    "  - Less sensitive to learning rate choice\n",
    "  - Generally faster convergence than SGD for this task\n",
    "- **Learning rate:** Start with 0.001 (standard default)\n",
    "\n",
    "**Learning Rate Scheduler:**\n",
    "- **ReduceLROnPlateau** is highly recommended\n",
    "  - Monitors validation loss (or accuracy)\n",
    "  - Reduces learning rate when metric plateaus\n",
    "  - Configuration: `factor=0.5`, `patience=3`\n",
    "  - Example: If val loss doesn't improve for 3 epochs, reduce LR by half\n",
    "- Why use it?\n",
    "  - Helps escape local minima\n",
    "  - Fine-tunes model in later stages\n",
    "  - Often gives 2-5% accuracy boost\n",
    "\n",
    "**Number of Epochs:**\n",
    "- Without augmentation: 15-20 epochs usually sufficient\n",
    "- With augmentation: 25-30 epochs (needs more time to learn variations)\n",
    "- Monitor validation metrics to decide when to stop\n",
    "\n",
    "**Early Stopping:**\n",
    "Implement early stopping with TWO conditions:\n",
    "1. **Target accuracy reached:** Stop if validation accuracy ≥ 85%\n",
    "2. **Patience limit:** Stop if no improvement for N epochs (e.g., 5)\n",
    "\n",
    "Why early stopping?\n",
    "- Prevents overfitting (training too long)\n",
    "- Saves time and computational resources\n",
    "- Automatically finds optimal training duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Training Loop Implementation\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "**1. Training Phase (each epoch):**\n",
    "- Set model to training mode: `model.train()`\n",
    "- For each batch:\n",
    "  - Move data to GPU (if available)\n",
    "  - Forward pass: get predictions\n",
    "  - Calculate loss\n",
    "  - Backward pass: compute gradients\n",
    "  - Optimizer step: update weights\n",
    "  - Track running loss and accuracy\n",
    "\n",
    "**2. Validation Phase (each epoch):**\n",
    "- Set model to evaluation mode: `model.eval()`\n",
    "- Disable gradient computation: `with torch.no_grad():`\n",
    "- For each batch:\n",
    "  - Move data to GPU\n",
    "  - Forward pass only (no backward pass)\n",
    "  - Calculate loss and accuracy\n",
    "  - Track metrics\n",
    "\n",
    "**3. Metrics to Track:**\n",
    "- Training loss (per epoch)\n",
    "- Training accuracy (per epoch)\n",
    "- Validation loss (per epoch)\n",
    "- Validation accuracy (per epoch)\n",
    "- Current learning rate\n",
    "- Epoch duration\n",
    "\n",
    "**4. Progress Monitoring:**\n",
    "- Use progress bars (tqdm) to show batch-level progress\n",
    "- Print epoch summaries\n",
    "- Save metrics history for later visualization\n",
    "\n",
    "**5. Model Checkpointing:**\n",
    "- Save the best model based on validation accuracy\n",
    "- Store both model weights and optimizer state\n",
    "- Allows you to resume training or use best model later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Training Experiments\n",
    "\n",
    "**Experiment 1: Baseline (No Augmentation)**\n",
    "\n",
    "Purpose:\n",
    "- Establish baseline performance\n",
    "- Understand model's raw capability\n",
    "- Identify overfitting patterns\n",
    "\n",
    "Configuration:\n",
    "- Transforms: Resize + Normalize only\n",
    "- Epochs: 15-20\n",
    "- All other settings same\n",
    "\n",
    "Expected Results:\n",
    "- Likely to see overfitting (train acc >> val acc)\n",
    "- Validation accuracy: 70-80%\n",
    "- Training curves may show divergence\n",
    "\n",
    "---\n",
    "\n",
    "**Experiment 2: With Augmentation**\n",
    "\n",
    "Purpose:\n",
    "- Improve generalization\n",
    "- Reduce overfitting\n",
    "- Achieve better validation performance\n",
    "\n",
    "Configuration:\n",
    "- Transforms: Resize + Augmentation + Normalize\n",
    "- Epochs: 25-30 (needs more time)\n",
    "- All other settings same\n",
    "\n",
    "Expected Results:\n",
    "- Reduced overfitting (smaller train-val gap)\n",
    "- Validation accuracy: 75-85%\n",
    "- More stable training curves\n",
    "- Training accuracy may be slightly lower (model sees harder examples)\n",
    "\n",
    "---\n",
    "\n",
    "**Comparing Results:**\n",
    "- Plot training curves side-by-side\n",
    "- Calculate improvement: (Aug_Val_Acc - No_Aug_Val_Acc)\n",
    "- Analyze overfitting gap: (Train_Acc - Val_Acc) for both\n",
    "- Document findings and insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 Model Evaluation\n",
    "\n",
    "**Training History Visualization:**\n",
    "\n",
    "Create plots showing:\n",
    "1. **Loss curves** (training and validation over epochs)\n",
    "2. **Accuracy curves** (training and validation over epochs)\n",
    "3. **Side-by-side comparison** (no aug vs with aug)\n",
    "\n",
    "What to look for:\n",
    "- **Overfitting indicators:**\n",
    "  - Training loss keeps decreasing\n",
    "  - Validation loss increases or plateaus\n",
    "  - Large gap between train and val accuracy\n",
    "  \n",
    "- **Good training:**\n",
    "  - Both losses decrease together\n",
    "  - Small gap between train and val accuracy\n",
    "  - Validation accuracy still improving or stable\n",
    "\n",
    "- **Underfitting indicators:**\n",
    "  - Both losses high\n",
    "  - Both accuracies low\n",
    "  - Not improving much over epochs\n",
    "\n",
    "---\n",
    "\n",
    "**Comprehensive Test Set Evaluation:**\n",
    "\n",
    "**1. Classification Report:**\n",
    "- Per-class metrics: Precision, Recall, F1-score\n",
    "- Identifies which classes perform well/poorly\n",
    "- Use `sklearn.metrics.classification_report`\n",
    "\n",
    "**Metric Definitions:**\n",
    "- **Precision:** Of predicted class X, how many are actually X?\n",
    "- **Recall:** Of actual class X, how many did we find?\n",
    "- **F1-score:** Harmonic mean of precision and recall\n",
    "\n",
    "**2. Confusion Matrix:**\n",
    "- Visualize with heatmap (seaborn)\n",
    "- Shows which classes are confused with each other\n",
    "- Diagonal = correct predictions\n",
    "- Off-diagonal = confusions\n",
    "\n",
    "Example insights:\n",
    "- \"Temple\" often confused with \"Palace\" → Similar architectural features\n",
    "- \"Fort\" rarely confused → Distinctive features\n",
    "\n",
    "**3. Per-Class Accuracy:**\n",
    "- Bar chart showing accuracy for each class\n",
    "- Helps identify problematic classes\n",
    "- Consider if low-performing classes have fewer training examples\n",
    "\n",
    "---\n",
    "\n",
    "**Individual Predictions:**\n",
    "\n",
    "**Single Image Prediction:**\n",
    "- Load a test image\n",
    "- Show top-K predictions with confidence scores\n",
    "- Example output:\n",
    "  - 1st: Temple (92%)\n",
    "  - 2nd: Palace (5%)\n",
    "  - 3rd: Monument (2%)\n",
    "\n",
    "**Batch Visualization:**\n",
    "- Display grid of test images with predictions\n",
    "- Color code: Green border = correct, Red border = incorrect\n",
    "- Include true label and predicted label\n",
    "- Include confidence score\n",
    "\n",
    "This helps you:\n",
    "- Understand failure modes\n",
    "- Build intuition about model behavior\n",
    "- Identify systematic errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9 Model Deployment\n",
    "\n",
    "**Save Your Best Model:**\n",
    "```python\n",
    "# Save the entire model\n",
    "torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Save additional info\n",
    "# - Class names\n",
    "# - Transforms used\n",
    "# - Model architecture details\n",
    "# - Training configuration\n",
    "```\n",
    "\n",
    "**Load and Use Later:**\n",
    "```python\n",
    "# Recreate model architecture\n",
    "# Load weights\n",
    "# Set to eval mode\n",
    "# Make predictions\n",
    "```\n",
    "\n",
    "**Inference Pipeline:**\n",
    "1. Load image from file\n",
    "2. Apply same preprocessing (resize, normalize)\n",
    "3. Convert to tensor and add batch dimension\n",
    "4. Move to same device as model\n",
    "5. Forward pass (no gradients needed)\n",
    "6. Get predicted class and confidence\n",
    "7. Return human-readable result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Tourism Recommendation System\n",
    "\n",
    "### Overview\n",
    "Build a collaborative filtering recommendation system to suggest tourist destinations based on user ratings and preferences.\n",
    "\n",
    "**Approach:** Item-based collaborative filtering using cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Data Loading and Understanding\n",
    "\n",
    "**Three datasets to work with:**\n",
    "\n",
    "**1. User Data (user.csv):**\n",
    "- User demographics: age, location\n",
    "- Understanding your user base\n",
    "\n",
    "**2. Tourism Places (tourism_with_id.xlsx):**\n",
    "- Place details: name, category, city, description\n",
    "- Metadata about tourist destinations\n",
    "\n",
    "**3. Ratings (tourism_rating.csv):**\n",
    "- User-place-rating triplets\n",
    "- The core data for collaborative filtering\n",
    "\n",
    "**Initial Exploration:**\n",
    "- Load each dataset into pandas DataFrame\n",
    "- Check shape, columns, data types\n",
    "- Display first few rows\n",
    "- Understand the schema and relationships\n",
    "\n",
    "**Key Questions:**\n",
    "- How many users? How many places? How many ratings?\n",
    "- What rating scale? (e.g., 1-5)\n",
    "- Are there user IDs and place IDs linking the datasets?\n",
    "- What categories of places exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Data Cleaning\n",
    "\n",
    "**Missing Value Analysis:**\n",
    "\n",
    "For each dataset:\n",
    "- Check `df.isnull().sum()` for each column\n",
    "- Understand why data might be missing\n",
    "- Decide on handling strategy:\n",
    "  - **Drop rows:** If critical data is missing\n",
    "  - **Fill with default:** For optional fields\n",
    "  - **Keep as-is:** If missing is informative\n",
    "\n",
    "**Duplicate Detection:**\n",
    "- Check for duplicate rows: `df.duplicated().sum()`\n",
    "- For ratings: Multiple ratings from same user for same place?\n",
    "  - Keep latest rating?\n",
    "  - Average them?\n",
    "  - Remove all duplicates?\n",
    "\n",
    "**Data Type Validation:**\n",
    "- User IDs, Place IDs: Should be integers or strings\n",
    "- Ratings: Should be numeric (integer or float)\n",
    "- Age: Should be reasonable range (e.g., 10-100)\n",
    "- Dates: Convert to datetime if present\n",
    "\n",
    "**Data Quality Checks:**\n",
    "- Rating range validation (e.g., should be 1-5)\n",
    "- Age range validation\n",
    "- Check for invalid or outlier values\n",
    "- Ensure referential integrity (all user_ids in ratings exist in users table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Exploratory Data Analysis\n",
    "\n",
    "**User Demographics Analysis:**\n",
    "\n",
    "**Age Distribution:**\n",
    "- Histogram showing age distribution\n",
    "- Box plot for outlier detection\n",
    "- Summary statistics (mean, median, std, min, max)\n",
    "- Insights: What age groups dominate your user base?\n",
    "\n",
    "**Geographic Distribution:**\n",
    "- Bar chart of top 15-20 locations\n",
    "- Where are your users from?\n",
    "- Does location correlate with tourism preferences?\n",
    "\n",
    "---\n",
    "\n",
    "**Tourism Places Analysis:**\n",
    "\n",
    "**Category Distribution:**\n",
    "- How many places in each category?\n",
    "- Pie chart or bar chart showing proportions\n",
    "- Example categories: Nature, Culture, Adventure, Religious, etc.\n",
    "\n",
    "**City Distribution:**\n",
    "- Which cities have the most tourist spots?\n",
    "- Bar chart of places per city\n",
    "- Understand geographic coverage\n",
    "\n",
    "**Category-City Relationships:**\n",
    "- Cross-tabulation: Which categories are popular in which cities?\n",
    "- Grouped bar charts\n",
    "- Insights: \"City A is known for temples, City B for nature\"\n",
    "\n",
    "---\n",
    "\n",
    "**Ratings Analysis:**\n",
    "\n",
    "**Overall Rating Distribution:**\n",
    "- Histogram of all ratings\n",
    "- Are ratings skewed (mostly high or low)?\n",
    "- Mean and median rating\n",
    "\n",
    "**User Activity:**\n",
    "- How many ratings per user?\n",
    "- Distribution: Some power users vs many casual users?\n",
    "- Identify very active vs inactive users\n",
    "\n",
    "**Place Popularity:**\n",
    "- How many ratings per place?\n",
    "- Some places very popular, others rarely rated?\n",
    "- This affects recommendation quality\n",
    "\n",
    "**Sparsity Calculation:**\n",
    "- Total possible ratings: (num_users × num_places)\n",
    "- Actual ratings: count of rating records\n",
    "- Sparsity: 1 - (actual / possible)\n",
    "- Typical recommendation systems: 95-99% sparse\n",
    "- This is a fundamental challenge in collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Advanced Ratings Analysis\n",
    "\n",
    "**Merge Datasets:**\n",
    "- Combine ratings with place details\n",
    "- Allows analysis by category, city, etc.\n",
    "- Use pandas `.merge()` on place_id\n",
    "\n",
    "**Most Loved Tourist Spots:**\n",
    "\n",
    "Approach:\n",
    "1. Filter places with minimum N ratings (e.g., 5+)\n",
    "   - Why? Places with 1-2 ratings might be outliers\n",
    "   - Statistical significance requires multiple data points\n",
    "2. Calculate average rating per place\n",
    "3. Sort by average rating (descending)\n",
    "4. Display top 10-20 places\n",
    "\n",
    "Visualization:\n",
    "- Horizontal bar chart\n",
    "- Include place name, city, category\n",
    "- Show average rating and number of ratings\n",
    "\n",
    "**Best Cities Analysis:**\n",
    "\n",
    "Two approaches:\n",
    "1. **Average rating per city:**\n",
    "   - Group ratings by city\n",
    "   - Calculate mean rating\n",
    "   - Which cities have highest-rated places?\n",
    "\n",
    "2. **Number of top-rated places per city:**\n",
    "   - Count how many highly-rated places each city has\n",
    "   - Which cities have most quality attractions?\n",
    "\n",
    "**Category Preferences:**\n",
    "\n",
    "- Average rating by category\n",
    "- Which types of places do users prefer?\n",
    "- Bar chart comparing categories\n",
    "- Insights for tourism development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Building the Recommendation System\n",
    "\n",
    "**Approach: Item-Based Collaborative Filtering**\n",
    "\n",
    "**Core Concept:**\n",
    "- \"Users who liked Place A also liked Place B\"\n",
    "- Find places similar to what the user already likes\n",
    "- Based on rating patterns, not content features\n",
    "\n",
    "**Why Item-Based (vs User-Based)?**\n",
    "- Item similarities more stable over time\n",
    "- Better scalability (fewer items than users typically)\n",
    "- Easier to explain: \"Because you liked X, you might like Y\"\n",
    "- Works better with sparse data\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1: Create User-Item Rating Matrix**\n",
    "\n",
    "Structure:\n",
    "- Rows: Users\n",
    "- Columns: Places\n",
    "- Values: Ratings (0 or NaN for missing)\n",
    "\n",
    "Example:\n",
    "```\n",
    "          Place1  Place2  Place3  Place4\n",
    "User1        5       0       4       0\n",
    "User2        4       3       0       5\n",
    "User3        0       4       5       3\n",
    "```\n",
    "\n",
    "Implementation:\n",
    "- Use pandas `.pivot_table()`\n",
    "- Handle missing values (fill with 0 or leave as NaN)\n",
    "- Result: Sparse matrix (mostly zeros/NaNs)\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Calculate Item-Item Similarity Matrix**\n",
    "\n",
    "**Similarity Metric: Cosine Similarity**\n",
    "\n",
    "Formula concept:\n",
    "- Measures angle between two rating vectors\n",
    "- Range: -1 (opposite) to +1 (identical)\n",
    "- Ignores magnitude, focuses on pattern\n",
    "\n",
    "Why cosine?\n",
    "- Scale-invariant (doesn't matter if one place has higher ratings overall)\n",
    "- Handles sparse data well (zeros don't dominate)\n",
    "- Computationally efficient\n",
    "- Standard in recommendation systems\n",
    "\n",
    "Implementation:\n",
    "- Use `sklearn.metrics.pairwise.cosine_similarity`\n",
    "- Input: rating matrix (transposed to compare items)\n",
    "- Output: Square matrix (place × place)\n",
    "\n",
    "Result:\n",
    "```\n",
    "          Place1  Place2  Place3\n",
    "Place1     1.00    0.85    0.62\n",
    "Place2     0.85    1.00    0.73\n",
    "Place3     0.62    0.73    1.00\n",
    "```\n",
    "Diagonal = 1.0 (each place perfectly similar to itself)\n",
    "\n",
    "**Visualization:**\n",
    "- Heatmap of similarity matrix\n",
    "- Bright cells = highly similar places\n",
    "- Helps understand place relationships\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Build Recommendation Function**\n",
    "\n",
    "**Input:** Place name (or ID)\n",
    "\n",
    "**Process:**\n",
    "1. **Find the place:**\n",
    "   - Look up place in your database\n",
    "   - Handle partial matching (e.g., user types \"taj\" → \"Taj Mahal\")\n",
    "   - Return error if place not found\n",
    "\n",
    "2. **Get similarity scores:**\n",
    "   - Extract row from similarity matrix for this place\n",
    "   - Now you have similarity to every other place\n",
    "\n",
    "3. **Sort by similarity:**\n",
    "   - Sort places by similarity score (descending)\n",
    "   - Exclude the place itself (similarity = 1.0)\n",
    "\n",
    "4. **Filter and rank:**\n",
    "   - Optionally filter by:\n",
    "     - Minimum number of ratings (quality filter)\n",
    "     - Category (e.g., only recommend same category)\n",
    "     - City (e.g., prioritize nearby places)\n",
    "   - Return top N (e.g., 5-10 recommendations)\n",
    "\n",
    "5. **Enrich results:**\n",
    "   - Include place details: name, city, category\n",
    "   - Include average rating\n",
    "   - Include similarity score\n",
    "   - Format nicely for display\n",
    "\n",
    "**Output Example:**\n",
    "```\n",
    "Recommendations for \"Taj Mahal\":\n",
    "1. Red Fort (Delhi) - History | Similarity: 0.92 | Avg Rating: 4.5\n",
    "2. Agra Fort (Agra) - History | Similarity: 0.89 | Avg Rating: 4.3\n",
    "3. Qutub Minar (Delhi) - Monument | Similarity: 0.85 | Avg Rating: 4.2\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Testing and Validation\n",
    "\n",
    "**Sanity Checks:**\n",
    "\n",
    "1. **Self-similarity:** Place should be most similar to itself (score = 1.0)\n",
    "2. **Symmetric similarity:** Similarity(A, B) = Similarity(B, A)\n",
    "3. **Reasonable recommendations:**\n",
    "   - Similar categories? (temple recommends temples)\n",
    "   - Same city/region?\n",
    "   - Similar rating patterns?\n",
    "\n",
    "**Test Cases:**\n",
    "\n",
    "1. **Popular place:** Should have many similar places\n",
    "2. **Niche place:** May have few similar places\n",
    "3. **Different categories:** Test recommendations across categories\n",
    "4. **Different cities:** Test geographic diversity\n",
    "\n",
    "**Quality Assessment:**\n",
    "\n",
    "Manual evaluation:\n",
    "- Do recommendations make sense?\n",
    "- Would you visit these places?\n",
    "- Are they truly similar?\n",
    "\n",
    "Quantitative metrics (advanced):\n",
    "- Precision@K: How many top-K recommendations are relevant?\n",
    "- Coverage: What % of catalog can be recommended?\n",
    "- Diversity: Are recommendations varied or all similar?\n",
    "\n",
    "**User-Based Recommendations (Extension):**\n",
    "\n",
    "Beyond place-to-place:\n",
    "- Given a user ID, what should we recommend?\n",
    "- Approach:\n",
    "  1. Find places user rated highly\n",
    "  2. Get recommendations for each\n",
    "  3. Aggregate and rank\n",
    "  4. Filter out already-visited places\n",
    "  5. Return top N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 System Limitations and Future Improvements\n",
    "\n",
    "**Current Limitations:**\n",
    "\n",
    "1. **Cold Start Problem:**\n",
    "   - **New users:** No rating history → Can't make personalized recommendations\n",
    "   - **New places:** Not enough ratings → Can't calculate similarity\n",
    "   - **Mitigation:** Use popularity-based recommendations initially\n",
    "\n",
    "2. **Sparsity:**\n",
    "   - Most user-place pairs have no rating\n",
    "   - Similarity calculations may be unreliable\n",
    "   - **Mitigation:** Require minimum ratings threshold\n",
    "\n",
    "3. **Popularity Bias:**\n",
    "   - Popular places dominate recommendations\n",
    "   - Niche places rarely recommended\n",
    "   - **Mitigation:** Boost diversity in ranking\n",
    "\n",
    "4. **No Content Understanding:**\n",
    "   - System doesn't understand what makes places similar\n",
    "   - Only uses rating patterns\n",
    "   - May recommend unrelated places with similar rating patterns\n",
    "\n",
    "---\n",
    "\n",
    "**Future Improvements:**\n",
    "\n",
    "**1. Hybrid Approach:**\n",
    "- Combine collaborative filtering with content-based filtering\n",
    "- Use place features: category, city, description, images\n",
    "- Helps with cold start and improves relevance\n",
    "\n",
    "**2. Matrix Factorization:**\n",
    "- Techniques like SVD (Singular Value Decomposition)\n",
    "- Learn latent factors (hidden features)\n",
    "- Better handling of sparsity\n",
    "- Can predict missing ratings\n",
    "\n",
    "**3. Deep Learning:**\n",
    "- Neural collaborative filtering\n",
    "- Embeddings for users and places\n",
    "- Can capture non-linear patterns\n",
    "\n",
    "**4. Context-Aware Recommendations:**\n",
    "- Consider time of year (seasonal attractions)\n",
    "- User location (recommend nearby)\n",
    "- User age group (family-friendly vs adventure)\n",
    "\n",
    "**5. Explanation Generation:**\n",
    "- Tell users WHY something was recommended\n",
    "- \"Because you liked X\" or \"Popular in your city\"\n",
    "- Builds trust and engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overall Project Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Organization\n",
    "\n",
    "**1. Modular Functions:**\n",
    "- Training loop → separate function\n",
    "- Evaluation → separate function\n",
    "- Recommendation generation → separate function\n",
    "- Visualization → reusable functions\n",
    "\n",
    "**2. Clear Documentation:**\n",
    "- Markdown cells explaining each section\n",
    "- Comments in code for complex logic\n",
    "- Docstrings for functions\n",
    "\n",
    "**3. Reproducibility:**\n",
    "- Set random seeds (Python, NumPy, PyTorch)\n",
    "- Document all hyperparameters\n",
    "- Save model configurations\n",
    "- Version your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Strategy\n",
    "\n",
    "**Start Simple, Then Iterate:**\n",
    "\n",
    "**Part 1 (Classification):**\n",
    "1. Get data loading working with small subset\n",
    "2. Build simple model (even without transfer learning)\n",
    "3. Train for 1-2 epochs to verify pipeline\n",
    "4. Add transfer learning\n",
    "5. Experiment with augmentation\n",
    "6. Fine-tune hyperparameters\n",
    "\n",
    "**Part 2 (Recommendations):**\n",
    "1. Load and clean data\n",
    "2. Create basic rating matrix\n",
    "3. Calculate similarity for 2-3 places manually\n",
    "4. Build full similarity matrix\n",
    "5. Create simple recommendation function\n",
    "6. Add filtering and ranking\n",
    "7. Improve user interface\n",
    "\n",
    "**Debug Systematically:**\n",
    "- Print shapes of tensors/matrices\n",
    "- Visualize intermediate results\n",
    "- Test on small examples first\n",
    "- Use assertions to catch errors early"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critical Thinking Questions\n",
    "\n",
    "**Throughout the project, ask yourself:**\n",
    "\n",
    "**Part 1:**\n",
    "- Does the model learn meaningful features or just memorize?\n",
    "- Why is this class harder to classify than others?\n",
    "- What would happen if I change the learning rate?\n",
    "- Am I overfitting? How can I tell?\n",
    "- Does the confusion matrix reveal systematic errors?\n",
    "\n",
    "**Part 2:**\n",
    "- Do these recommendations make intuitive sense?\n",
    "- Why are these places similar according to the algorithm?\n",
    "- What happens with very popular vs unpopular places?\n",
    "- How sparse is my data? Does it affect quality?\n",
    "- Would a different similarity metric work better?\n",
    "\n",
    "**General:**\n",
    "- What are the ethical implications of this system?\n",
    "- How would this work in production?\n",
    "- What could go wrong?\n",
    "- How would I explain this to a non-technical person?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Image Classification\n",
    "\n",
    "**Core Concepts:**\n",
    "- Transfer learning is powerful for small datasets\n",
    "- Data augmentation reduces overfitting\n",
    "- Always compare with/without to measure impact\n",
    "- Multiple evaluation metrics reveal different insights\n",
    "- Visual inspection catches things metrics miss\n",
    "\n",
    "**Skills Developed:**\n",
    "- PyTorch model building and training\n",
    "- Transfer learning implementation\n",
    "- Data augmentation strategies\n",
    "- Training monitoring and debugging\n",
    "- Comprehensive model evaluation\n",
    "- Confusion matrix interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Recommendation System\n",
    "\n",
    "**Core Concepts:**\n",
    "- Collaborative filtering finds patterns in behavior\n",
    "- Sparsity is a fundamental challenge\n",
    "- Item-based vs user-based have different tradeoffs\n",
    "- Similarity metrics matter (cosine, Pearson, Jaccard)\n",
    "- Filtering improves recommendation quality\n",
    "- Cold start requires special handling\n",
    "\n",
    "**Skills Developed:**\n",
    "- Pandas data manipulation and merging\n",
    "- Matrix operations and transformations\n",
    "- Similarity calculation\n",
    "- Recommendation algorithm implementation\n",
    "- Data sparsity handling\n",
    "- System design thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Next Steps\n\n1. **Read the project requirements carefully**\n2. **Set up your environment** (Python, PyTorch, pandas, scikit-learn)\n3. **⚠️ Handle corrupted images** - Add `ImageFile.LOAD_TRUNCATED_IMAGES = True` at the start\n4. **Start with Part 1 or Part 2** (they're independent)\n5. **Follow the phases outlined above**\n6. **Build incrementally** - test each component\n7. **Document your decisions and findings**\n8. **Ask questions when stuck** - debugging is part of learning\n\n**Remember:**\n- It's okay if your first attempt doesn't work perfectly\n- Experimentation and iteration are key\n- Understanding > Memorization\n- The journey teaches more than the destination\n- **Real-world data is messy** - learning to handle it is a valuable skill!\n\n**Common Issues You May Encounter:**\n\n- **Corrupted images:** Use `ImageFile.LOAD_TRUNCATED_IMAGES = True` (see Section 1.1.1)\n- **Out of GPU memory:** Reduce batch size from 32 to 16 or 8\n- **Training too slow:** Consider using a subset of data first to test your pipeline\n- **Module not found:** Install missing packages with pip\n- **Can't find dataset:** Ensure you've extracted the ZIP file correctly\n\nGood luck! You're building real AI systems that could preserve cultural heritage and help millions of tourists. That's pretty amazing."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Read the project requirements carefully**\n",
    "2. **Set up your environment** (Python, PyTorch, pandas, scikit-learn)\n",
    "3. **Start with Part 1 or Part 2** (they're independent)\n",
    "4. **Follow the phases outlined above**\n",
    "5. **Build incrementally** - test each component\n",
    "6. **Document your decisions and findings**\n",
    "7. **Ask questions when stuck** - debugging is part of learning\n",
    "\n",
    "**Remember:**\n",
    "- It's okay if your first attempt doesn't work perfectly\n",
    "- Experimentation and iteration are key\n",
    "- Understanding > Memorization\n",
    "- The journey teaches more than the destination\n",
    "\n",
    "Good luck! You're building real AI systems that could preserve cultural heritage and help millions of tourists. That's pretty amazing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}