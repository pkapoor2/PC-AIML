{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone 3: Approach Overview\n",
    "## Restaurant Sales Forecasting with Time Series Analysis\n",
    "\n",
    "This notebook provides a high-level overview of how to approach the Capstone 3 project. It outlines the key steps, decisions, and methodologies without providing complete code solutions.\n",
    "\n",
    "**Goal:** Help you understand the problem-solving framework and key considerations for time series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "### Business Problem\n",
    "You have 3 years of daily sales data (2019-2021) from 6 restaurants selling 100 different menu items. Your task is to:\n",
    "1. Analyze historical sales patterns\n",
    "2. Build forecasting models to predict future sales\n",
    "3. Provide business insights and recommendations\n",
    "\n",
    "### Why This Matters\n",
    "- **Inventory Management:** Order the right amount of ingredients\n",
    "- **Staffing:** Schedule appropriate number of employees\n",
    "- **Financial Planning:** Forecast revenue for budgeting\n",
    "- **Marketing:** Plan promotions based on predicted slow periods\n",
    "\n",
    "### Datasets\n",
    "1. **sales.csv** - Daily sales records (~110K rows)\n",
    "   - date, item_id, price, item_count\n",
    "2. **items.csv** - Menu item details (100 items)\n",
    "   - id, store_id, name, kcal, cost\n",
    "3. **resturants.csv** - Restaurant information (6 locations)\n",
    "   - id, name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Data Understanding and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Initial Data Loading\n",
    "\n",
    "**First Steps:**\n",
    "- Load all three CSV files using pandas\n",
    "- Check the shape of each dataset\n",
    "- Examine first few rows\n",
    "- Understand column data types\n",
    "\n",
    "**Key Questions to Answer:**\n",
    "- How many sales records do you have?\n",
    "- What is the date range of the data?\n",
    "- Are there any missing values?\n",
    "- Do the datasets link together properly?\n",
    "\n",
    "**Critical Step: Date Conversion**\n",
    "- Convert the 'date' column to datetime format\n",
    "- This is ESSENTIAL for time series analysis\n",
    "- Use `pd.to_datetime()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data Quality Checks\n",
    "\n",
    "**Important Issues to Look For:**\n",
    "\n",
    "**1. Zero Sales Records:**\n",
    "- You'll likely see many rows with `item_count = 0`\n",
    "- This means the item was available but not sold that day\n",
    "- **Decision:** Keep or remove these records?\n",
    "  - For aggregate analysis: Usually OK to keep\n",
    "  - For item-level analysis: May want to filter out\n",
    "  - Document your choice!\n",
    "\n",
    "**2. Data Structure:**\n",
    "- Each day should have entries for all 100 items (some with 0 sales)\n",
    "- Total records = days × items = ~1,095 days × 100 items = ~109,500\n",
    "- Verify this makes sense\n",
    "\n",
    "**3. Missing Dates:**\n",
    "- Are there any gaps in the date sequence?\n",
    "- Check: `date_range = pd.date_range(start=min_date, end=max_date)`\n",
    "- Compare expected vs actual dates\n",
    "\n",
    "**4. Outliers:**\n",
    "- Unusually high sales days?\n",
    "- Negative values? (shouldn't exist)\n",
    "- Use `.describe()` to spot anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Merging Datasets\n",
    "\n",
    "**Why Merge?**\n",
    "- Sales data only has IDs (item_id)\n",
    "- Need item names and restaurant names for interpretation\n",
    "- Enables more meaningful analysis\n",
    "\n",
    "**How to Merge:**\n",
    "```python\n",
    "# Pseudo-code approach:\n",
    "# 1. Merge sales with items on item_id\n",
    "# 2. Merge result with restaurants on store_id\n",
    "# 3. Calculate revenue = price × item_count\n",
    "```\n",
    "\n",
    "**Validation:**\n",
    "- Check merged dataset has same number of rows as sales\n",
    "- Verify no NaN values in restaurant/item names\n",
    "- If NaNs appear, investigate data quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Overall Trends:**\n",
    "\n",
    "**Daily Aggregation:**\n",
    "- Group by date, sum all items and revenue\n",
    "- Plot time series: date vs total items sold\n",
    "- Plot time series: date vs total revenue\n",
    "- Look for:\n",
    "  - Trends (increasing/decreasing over time?)\n",
    "  - Seasonality (weekly, monthly, yearly patterns?)\n",
    "  - Outliers (unusual spikes or drops?)\n",
    "\n",
    "**Questions to Explore:**\n",
    "- Is business growing or declining?\n",
    "- Are there seasonal effects?\n",
    "- Any impact from 2020 events?\n",
    "\n",
    "---\n",
    "\n",
    "**Restaurant-Level Analysis:**\n",
    "\n",
    "- Which restaurant sells the most items?\n",
    "- Which generates the most revenue?\n",
    "- Are some restaurants underperforming?\n",
    "\n",
    "**Visualizations:**\n",
    "- Bar charts: Total sales by restaurant\n",
    "- Bar charts: Total revenue by restaurant\n",
    "- Time series: Individual restaurant trends\n",
    "\n",
    "---\n",
    "\n",
    "**Item-Level Analysis:**\n",
    "\n",
    "**Best Sellers:**\n",
    "- Top 20 items by quantity sold\n",
    "- Top 20 items by revenue generated\n",
    "- Compare: Do high-volume items = high-revenue items?\n",
    "\n",
    "**Insights to Find:**\n",
    "- Which items drive the business?\n",
    "- Are expensive items selling well?\n",
    "- Any items with zero/minimal sales (candidates for removal)?\n",
    "\n",
    "---\n",
    "\n",
    "**Temporal Patterns:**\n",
    "\n",
    "**Monthly Trends:**\n",
    "- Aggregate sales by year and month\n",
    "- Plot monthly sales over 3 years\n",
    "- Look for seasonal patterns (e.g., higher sales in certain months)\n",
    "\n",
    "**Day of Week Patterns:**\n",
    "- Calculate average sales for each day (Mon-Sun)\n",
    "- Are weekends busier than weekdays?\n",
    "- This is crucial for staffing decisions!\n",
    "\n",
    "**Visualizations:**\n",
    "- Line plots for monthly trends\n",
    "- Bar charts for day-of-week averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Feature Engineering for Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Understanding Time Series Features\n",
    "\n",
    "**Why Feature Engineering?**\n",
    "\n",
    "Unlike regular machine learning, time series has special characteristics:\n",
    "- **Temporal dependency:** Today's sales depend on yesterday's\n",
    "- **Seasonality:** Patterns repeat (weekly, monthly, yearly)\n",
    "- **Trends:** Long-term increases or decreases\n",
    "\n",
    "Machine learning models don't automatically understand \"time\" - we must create features that capture these patterns!\n",
    "\n",
    "**Three Categories of Features:**\n",
    "1. **Time-based features** (from date)\n",
    "2. **Lag features** (past values)\n",
    "3. **Rolling window features** (moving statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Time-Based Features\n",
    "\n",
    "**Extract from Date Column:**\n",
    "\n",
    "**Basic Temporal Features:**\n",
    "- `year`: 2019, 2020, 2021\n",
    "- `month`: 1-12\n",
    "- `day`: 1-31\n",
    "- `day_of_week`: 0 (Monday) to 6 (Sunday)\n",
    "- `day_of_year`: 1-365\n",
    "- `week_of_year`: 1-52\n",
    "- `quarter`: 1-4\n",
    "\n",
    "**Why Each Feature Matters:**\n",
    "- `month`: Captures yearly seasonality (summer vs winter)\n",
    "- `day_of_week`: Captures weekly patterns (weekend vs weekday)\n",
    "- `quarter`: Captures quarterly business cycles\n",
    "\n",
    "---\n",
    "\n",
    "**Binary Flags:**\n",
    "- `is_weekend`: 1 if Saturday/Sunday, 0 otherwise\n",
    "- `is_month_start`: 1 if first day of month\n",
    "- `is_month_end`: 1 if last day of month\n",
    "\n",
    "**Why Binary Flags?**\n",
    "- Highlight special periods that may have different patterns\n",
    "- Month-end might have rush due to people getting paid\n",
    "- Weekends typically have different patterns\n",
    "\n",
    "---\n",
    "\n",
    "**Cyclical Features (Advanced but Important!):**\n",
    "\n",
    "**Problem:** Month=1 and Month=12 are actually close (January and December)\n",
    "- But numerically, 1 and 12 look far apart\n",
    "- This confuses machine learning models!\n",
    "\n",
    "**Solution:** Sine/Cosine Encoding\n",
    "```python\n",
    "# Pseudo-code\n",
    "month_sin = sin(2 * π * month / 12)\n",
    "month_cos = cos(2 * π * month / 12)\n",
    "```\n",
    "\n",
    "**Why This Works:**\n",
    "- Creates circular representation\n",
    "- December (12) and January (1) are now mathematically close\n",
    "- Apply to: month, day_of_week, hour (if you had hourly data)\n",
    "\n",
    "**When to Use:**\n",
    "- Essential for capturing seasonality in ML models\n",
    "- Random Forest and XGBoost benefit greatly from this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Lag Features\n",
    "\n",
    "**Concept:**\n",
    "- Use past values as predictors for future values\n",
    "- \"Yesterday's sales help predict today's sales\"\n",
    "\n",
    "**Common Lags to Create:**\n",
    "- **Lag 1:** Previous day's sales\n",
    "- **Lag 7:** Sales from 1 week ago (same day of week!)\n",
    "- **Lag 14:** Sales from 2 weeks ago\n",
    "- **Lag 30:** Sales from ~1 month ago\n",
    "\n",
    "**Why These Specific Lags?**\n",
    "- **Lag 1:** Immediate past is often most predictive\n",
    "- **Lag 7:** Captures weekly seasonality (e.g., every Monday is similar)\n",
    "- **Lag 14, 30:** Captures longer-term patterns\n",
    "\n",
    "**How to Create:**\n",
    "```python\n",
    "# Pseudo-code\n",
    "data['sales_lag_1'] = data['sales'].shift(1)\n",
    "data['sales_lag_7'] = data['sales'].shift(7)\n",
    "```\n",
    "\n",
    "**Important Caveat:**\n",
    "- Lag features create NaN values at the beginning\n",
    "- First row has no lag_1 (no previous day)\n",
    "- First 7 rows have no lag_7\n",
    "- **You'll need to drop these NaN rows later!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Rolling Window Features\n",
    "\n",
    "**Concept:**\n",
    "- Calculate statistics over a moving window\n",
    "- Captures recent trends and patterns\n",
    "\n",
    "**Common Rolling Features:**\n",
    "\n",
    "**7-day rolling mean:**\n",
    "- Average of last 7 days\n",
    "- Smooths out daily noise\n",
    "- Represents \"recent trend\"\n",
    "\n",
    "**7-day rolling std:**\n",
    "- Standard deviation of last 7 days\n",
    "- Captures volatility/variability\n",
    "- High std = unstable sales\n",
    "\n",
    "**7-day rolling min/max:**\n",
    "- Minimum and maximum in last 7 days\n",
    "- Shows range of recent performance\n",
    "\n",
    "**Common Windows:**\n",
    "- **7 days:** Recent week's pattern\n",
    "- **14 days:** Two-week trend\n",
    "- **30 days:** Monthly trend\n",
    "\n",
    "**How to Create:**\n",
    "```python\n",
    "# Pseudo-code\n",
    "data['sales_rolling_mean_7'] = data['sales'].rolling(window=7).mean()\n",
    "data['sales_rolling_std_7'] = data['sales'].rolling(window=7).std()\n",
    "```\n",
    "\n",
    "**Important Notes:**\n",
    "- Also creates NaN values at the beginning\n",
    "- First 7 rows won't have 7-day rolling mean\n",
    "- Be consistent with how you handle NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Handling Missing Values from Feature Engineering\n",
    "\n",
    "**After creating lag and rolling features, you'll have NaNs!**\n",
    "\n",
    "**Approaches:**\n",
    "\n",
    "**Option 1: Drop Rows with NaN (Recommended)**\n",
    "- Simple and clean\n",
    "- Use `df.dropna()`\n",
    "- You'll lose ~30-40 days of data (from the beginning)\n",
    "- With 3 years of data, this is acceptable\n",
    "\n",
    "**Option 2: Forward Fill**\n",
    "- Fill NaN with previous valid value\n",
    "- Less ideal for time series (introduces bias)\n",
    "\n",
    "**Option 3: Use Shorter Lags Initially**\n",
    "- Start with only lag 1, 2, 3 to minimize NaNs\n",
    "- Trade-off: Less feature richness\n",
    "\n",
    "**Best Practice:**\n",
    "- Drop NaN rows\n",
    "- Document how many rows removed\n",
    "- Ensure you still have sufficient training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Time Series Forecasting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Train/Test Split - TIME SERIES IS DIFFERENT!\n",
    "\n",
    "**Critical Rule: NEVER use random splitting for time series!**\n",
    "\n",
    "**Why Not Random?**\n",
    "- Would leak future information into training\n",
    "- Violates temporal causality\n",
    "- Gives artificially good (but useless) results\n",
    "\n",
    "**Correct Approach: Temporal Split**\n",
    "\n",
    "```\n",
    "Timeline: |-------- Training --------|--- Test ---|\n",
    "          2019-01      ...        2021-09  2021-12\n",
    "```\n",
    "\n",
    "**Common Split Strategies:**\n",
    "\n",
    "**1. Last N Days as Test:**\n",
    "- Last 90 days (3 months) for testing\n",
    "- Everything before for training\n",
    "- Simple and effective\n",
    "\n",
    "**2. Percentage-Based:**\n",
    "- Last 20% of data as test\n",
    "- First 80% as train\n",
    "- Ensures temporal order\n",
    "\n",
    "**3. Specific Date Split:**\n",
    "- Train: 2019-2020\n",
    "- Test: 2021\n",
    "- Clean yearly boundary\n",
    "\n",
    "**How to Implement:**\n",
    "```python\n",
    "# Pseudo-code\n",
    "split_date = '2021-10-01'\n",
    "train = data[data['date'] <= split_date]\n",
    "test = data[data['date'] > split_date]\n",
    "```\n",
    "\n",
    "**Validation:**\n",
    "- Verify train dates < test dates\n",
    "- Check no overlap\n",
    "- Ensure sufficient data in both sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baseline Model: Moving Average\n",
    "\n",
    "**Why Start with a Baseline?**\n",
    "- Establishes minimum performance\n",
    "- Simple to understand and implement\n",
    "- Provides comparison point for complex models\n",
    "\n",
    "**Simple Moving Average:**\n",
    "\n",
    "**Concept:**\n",
    "- Predict tomorrow's sales = average of last N days\n",
    "- Common windows: 7, 14, 30 days\n",
    "\n",
    "**Example (7-day MA):**\n",
    "```\n",
    "Past 7 days sales: [100, 105, 98, 110, 95, 102, 108]\n",
    "Prediction for tomorrow: Average = 102.6\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- Extremely simple\n",
    "- No training needed\n",
    "- Interpretable to non-technical stakeholders\n",
    "\n",
    "**Cons:**\n",
    "- Doesn't capture complex patterns\n",
    "- Lags behind trends\n",
    "- No seasonality awareness\n",
    "\n",
    "**Expected Performance:**\n",
    "- R² score: 0.3 - 0.6 (rough estimate)\n",
    "- Good enough for very stable data\n",
    "- Usually outperformed by ML models\n",
    "\n",
    "**Implementation Approach:**\n",
    "- For each test day:\n",
    "  - Take last 7 days of actual sales\n",
    "  - Calculate average\n",
    "  - That's your prediction\n",
    "- Important: Use actual values (not predictions) for rolling window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Machine Learning Model: Random Forest\n",
    "\n",
    "**Why Random Forest for Time Series?**\n",
    "- Handles non-linear patterns well\n",
    "- Robust to outliers\n",
    "- Provides feature importance (interpretability)\n",
    "- No assumptions about data distribution\n",
    "- Generally good out-of-the-box performance\n",
    "\n",
    "**How It Works (Simplified):**\n",
    "- Builds many decision trees\n",
    "- Each tree learns different patterns\n",
    "- Final prediction = average of all trees\n",
    "- Reduces overfitting through ensemble\n",
    "\n",
    "---\n",
    "\n",
    "**Key Hyperparameters:**\n",
    "\n",
    "**1. n_estimators (Number of trees)**\n",
    "- Range: 50-500\n",
    "- Recommendation: 100 is good starting point\n",
    "- More trees = more computation, but usually better performance\n",
    "- Diminishing returns after ~200\n",
    "\n",
    "**2. max_depth (Tree depth)**\n",
    "- Range: 5-20\n",
    "- Recommendation: 10 for this problem\n",
    "- Deeper = more complex patterns, but risk overfitting\n",
    "- Shallower = simpler, more generalized\n",
    "\n",
    "**3. min_samples_split**\n",
    "- Minimum samples to split a node\n",
    "- Recommendation: 5\n",
    "- Prevents overfitting on small groups\n",
    "\n",
    "**4. min_samples_leaf**\n",
    "- Minimum samples in each leaf\n",
    "- Recommendation: 2-4\n",
    "- Smooths predictions\n",
    "\n",
    "---\n",
    "\n",
    "**Training Process:**\n",
    "\n",
    "```python\n",
    "# Pseudo-code structure:\n",
    "# 1. Prepare features and target\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['sales']\n",
    "\n",
    "# 2. Initialize model\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=10, ...)\n",
    "\n",
    "# 3. Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "X_test = test_data[feature_columns]\n",
    "predictions = model.predict(X_test)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Feature Importance:**\n",
    "\n",
    "**Why It Matters:**\n",
    "- Tells you which features drive predictions\n",
    "- Business insights (what actually affects sales?)\n",
    "- Feature selection (remove unimportant features)\n",
    "\n",
    "**How to Extract:**\n",
    "```python\n",
    "# Pseudo-code\n",
    "importances = model.feature_importances_\n",
    "# Create dataframe, sort by importance, visualize\n",
    "```\n",
    "\n",
    "**Expected Important Features:**\n",
    "- Lag features (especially lag_1, lag_7)\n",
    "- Rolling means\n",
    "- Day of week\n",
    "- Month (seasonality)\n",
    "\n",
    "---\n",
    "\n",
    "**Expected Performance:**\n",
    "- R² score: 0.6 - 0.85 (depending on data quality)\n",
    "- Should significantly outperform baseline\n",
    "- MAE: Typically 15-25% of average daily sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Advanced Model: XGBoost (Optional)\n",
    "\n",
    "**What is XGBoost?**\n",
    "- Extreme Gradient Boosting\n",
    "- State-of-the-art machine learning algorithm\n",
    "- Often wins Kaggle competitions\n",
    "- Similar to Random Forest but builds trees sequentially\n",
    "\n",
    "**How It Differs from Random Forest:**\n",
    "- **Random Forest:** Build all trees independently, average results\n",
    "- **XGBoost:** Build trees sequentially, each fixes previous tree's errors\n",
    "\n",
    "**Pros:**\n",
    "- Often better performance than Random Forest\n",
    "- Built-in regularization (prevents overfitting)\n",
    "- Handles missing values well\n",
    "- Fast and efficient\n",
    "\n",
    "**Cons:**\n",
    "- More hyperparameters to tune\n",
    "- Slightly more complex to understand\n",
    "- Requires separate installation (`pip install xgboost`)\n",
    "\n",
    "---\n",
    "\n",
    "**Key Hyperparameters:**\n",
    "\n",
    "**1. n_estimators**\n",
    "- Same as Random Forest\n",
    "- Recommendation: 100-200\n",
    "\n",
    "**2. learning_rate (unique to boosting)**\n",
    "- Range: 0.01 - 0.3\n",
    "- Recommendation: 0.1\n",
    "- Lower = slower learning, more trees needed, but often better\n",
    "- Higher = faster, but risk of overfitting\n",
    "\n",
    "**3. max_depth**\n",
    "- Recommendation: 5-8 (shallower than Random Forest)\n",
    "- Boosting compensates with more trees\n",
    "\n",
    "**4. subsample**\n",
    "- Fraction of samples used per tree\n",
    "- Recommendation: 0.8\n",
    "- Prevents overfitting\n",
    "\n",
    "**5. colsample_bytree**\n",
    "- Fraction of features used per tree\n",
    "- Recommendation: 0.8\n",
    "- Adds randomness, reduces overfitting\n",
    "\n",
    "---\n",
    "\n",
    "**When to Use XGBoost:**\n",
    "- Want to squeeze out extra performance\n",
    "- Have time to tune hyperparameters\n",
    "- Working on a competition or critical application\n",
    "\n",
    "**When Random Forest is Fine:**\n",
    "- Good enough performance for business needs\n",
    "- Easier to explain to stakeholders\n",
    "- Less tuning required\n",
    "\n",
    "**Expected Performance:**\n",
    "- Often 2-5% better R² than Random Forest\n",
    "- Marginal but measurable improvement\n",
    "- Most improvement on complex patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Model Evaluation Metrics\n",
    "\n",
    "**Why Multiple Metrics?**\n",
    "- Each metric reveals different aspects of performance\n",
    "- No single metric tells the whole story\n",
    "- Different stakeholders care about different metrics\n",
    "\n",
    "---\n",
    "\n",
    "**1. Mean Absolute Error (MAE)**\n",
    "\n",
    "**Formula:** Average of |actual - predicted|\n",
    "\n",
    "**What It Means:**\n",
    "- \"On average, predictions are off by X items\"\n",
    "- In same units as target (number of items)\n",
    "- Easy to interpret for business\n",
    "\n",
    "**Example:**\n",
    "- MAE = 50 items\n",
    "- \"Our predictions are off by about 50 items per day\"\n",
    "\n",
    "**Pros:**\n",
    "- Intuitive\n",
    "- Not sensitive to outliers\n",
    "- Direct business meaning\n",
    "\n",
    "**When to Use:**\n",
    "- Communicating with non-technical stakeholders\n",
    "- When all errors matter equally\n",
    "\n",
    "---\n",
    "\n",
    "**2. Root Mean Squared Error (RMSE)**\n",
    "\n",
    "**Formula:** Square root of average of (actual - predicted)²\n",
    "\n",
    "**What It Means:**\n",
    "- Similar to MAE but penalizes large errors more\n",
    "- Also in same units as target\n",
    "\n",
    "**Difference from MAE:**\n",
    "- RMSE always ≥ MAE\n",
    "- Gap between RMSE and MAE indicates outliers\n",
    "- Large gap = you have some big misses\n",
    "\n",
    "**When to Use:**\n",
    "- When large errors are particularly bad\n",
    "- Standard in many ML applications\n",
    "\n",
    "---\n",
    "\n",
    "**3. R² Score (Coefficient of Determination)**\n",
    "\n",
    "**Formula:** 1 - (Sum of squared residuals / Total variance)\n",
    "\n",
    "**Range:** -∞ to 1 (usually 0 to 1)\n",
    "\n",
    "**Interpretation:**\n",
    "- R² = 0.75 → \"Model explains 75% of variance\"\n",
    "- R² = 1.0 → Perfect predictions\n",
    "- R² = 0.0 → No better than predicting the mean\n",
    "- R² < 0 → Worse than predicting the mean\n",
    "\n",
    "**What's Good?**\n",
    "- Time series: 0.6+ is decent, 0.8+ is excellent\n",
    "- Context-dependent\n",
    "\n",
    "**Pros:**\n",
    "- Scale-independent (compare across datasets)\n",
    "- Percentage of variance explained\n",
    "\n",
    "**Cons:**\n",
    "- Less intuitive than MAE\n",
    "- Can be misleading with outliers\n",
    "\n",
    "---\n",
    "\n",
    "**4. Mean Absolute Percentage Error (MAPE) - Optional**\n",
    "\n",
    "**Formula:** Average of |actual - predicted| / |actual| × 100\n",
    "\n",
    "**What It Means:**\n",
    "- \"On average, predictions are off by X%\"\n",
    "- Percentage error\n",
    "\n",
    "**Example:**\n",
    "- MAPE = 15%\n",
    "- \"Predictions are typically within 15% of actual\"\n",
    "\n",
    "**When to Use:**\n",
    "- Comparing across different scales\n",
    "- Business-friendly metric\n",
    "\n",
    "**Caution:**\n",
    "- Undefined when actual = 0\n",
    "- Sensitive to small denominators\n",
    "\n",
    "---\n",
    "\n",
    "**Which Metrics to Report?**\n",
    "\n",
    "**Minimum:**\n",
    "- MAE (business interpretation)\n",
    "- R² (model quality)\n",
    "\n",
    "**Comprehensive:**\n",
    "- MAE, RMSE, R², MAPE\n",
    "- Shows complete picture\n",
    "\n",
    "**For Stakeholders:**\n",
    "- Focus on MAE or MAPE\n",
    "- \"We predict sales within ±50 items on average\"\n",
    "- Much clearer than R²!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model Comparison and Selection\n",
    "\n",
    "**Create a Comparison Table:**\n",
    "\n",
    "```\n",
    "Model              MAE    RMSE    R²     Training Time\n",
    "──────────────────────────────────────────────────────\n",
    "Moving Average     X      X       X      < 1 sec\n",
    "Random Forest      X      X       X      30 sec\n",
    "XGBoost            X      X       X      45 sec\n",
    "```\n",
    "\n",
    "**Selection Criteria:**\n",
    "\n",
    "**Best Performance:**\n",
    "- Choose model with highest R²\n",
    "- Or lowest MAE/RMSE\n",
    "- Usually XGBoost or Random Forest\n",
    "\n",
    "**Simplicity vs Performance:**\n",
    "- If Random Forest is 1% worse than XGBoost, but much simpler?\n",
    "- Consider the trade-off\n",
    "- Easier to explain and maintain\n",
    "\n",
    "**Production Considerations:**\n",
    "- Training time important for daily retraining?\n",
    "- Prediction speed critical?\n",
    "- Available computational resources?\n",
    "\n",
    "**Recommendation:**\n",
    "- Start with Random Forest\n",
    "- Try XGBoost if you want best performance\n",
    "- Keep baseline for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Model Interpretation and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Prediction Visualization\n",
    "\n",
    "**Time Series Plot:**\n",
    "\n",
    "Essential visualization:\n",
    "- X-axis: Date\n",
    "- Y-axis: Sales (items sold)\n",
    "- Two lines:\n",
    "  - Actual sales (solid line)\n",
    "  - Predicted sales (dashed line)\n",
    "\n",
    "**What to Look For:**\n",
    "- Do predictions follow actual trends?\n",
    "- Are predictions consistently high or low (bias)?\n",
    "- Do predictions capture peaks and valleys?\n",
    "- How far off are they typically?\n",
    "\n",
    "**Good Signs:**\n",
    "- Lines track each other closely\n",
    "- Predictions capture general trend\n",
    "- Errors are random (not systematic)\n",
    "\n",
    "**Warning Signs:**\n",
    "- Predictions always lag behind actuals\n",
    "- Predictions miss major spikes/drops\n",
    "- Consistent over/under-prediction\n",
    "\n",
    "---\n",
    "\n",
    "**Zoomed Views:**\n",
    "\n",
    "Create multiple plots:\n",
    "- **Full test period:** Overall performance\n",
    "- **First 2 weeks:** Detailed view\n",
    "- **Last 2 weeks:** Recent performance\n",
    "- **Worst period:** Where model struggles\n",
    "\n",
    "Helps identify specific issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Residual Analysis\n",
    "\n",
    "**What are Residuals?**\n",
    "- Residual = Actual - Predicted\n",
    "- The \"error\" for each prediction\n",
    "- Positive = under-predicted\n",
    "- Negative = over-predicted\n",
    "\n",
    "**Why Analyze Residuals?**\n",
    "- Reveals patterns in errors\n",
    "- Indicates model deficiencies\n",
    "- Suggests improvements\n",
    "\n",
    "---\n",
    "\n",
    "**Residual Plot:**\n",
    "\n",
    "**X-axis:** Predicted values  \n",
    "**Y-axis:** Residuals  \n",
    "**Add:** Horizontal line at y=0\n",
    "\n",
    "**Ideal Pattern:**\n",
    "- Random scatter around y=0\n",
    "- No clear pattern\n",
    "- Constant variance (homoscedasticity)\n",
    "\n",
    "**Problem Patterns:**\n",
    "\n",
    "**1. Funnel Shape:**\n",
    "```\n",
    "   |     *   *\n",
    "   |   *   *\n",
    " 0 |──*──*────\n",
    "   |   *   *\n",
    "   |     *   *\n",
    "   └──────────→ predicted\n",
    "```\n",
    "- Variance increases with prediction\n",
    "- Model less reliable for high values\n",
    "- Solution: Log transformation\n",
    "\n",
    "**2. Curved Pattern:**\n",
    "```\n",
    "   |   *     *\n",
    "   |  *  *  *\n",
    " 0 |──*───*────\n",
    "   | *     *\n",
    "   |*       *\n",
    "   └──────────→\n",
    "```\n",
    "- Non-linear relationship missed\n",
    "- Need more complex features\n",
    "\n",
    "**3. Clusters:**\n",
    "- Distinct groups in residuals\n",
    "- Missing categorical variable?\n",
    "- Different restaurants/items behave differently\n",
    "\n",
    "---\n",
    "\n",
    "**Residual Distribution:**\n",
    "\n",
    "**Histogram of Residuals:**\n",
    "\n",
    "**Ideal:**\n",
    "- Bell-shaped (normal distribution)\n",
    "- Centered at 0\n",
    "- Symmetric\n",
    "\n",
    "**Problems:**\n",
    "- **Skewed:** Systematic over/under-prediction\n",
    "- **Bimodal:** Two different regimes\n",
    "- **Heavy tails:** Many large errors (outliers)\n",
    "\n",
    "**Statistics to Calculate:**\n",
    "- Mean residual (should be ~0)\n",
    "- Std dev (spread of errors)\n",
    "- Min/max (worst errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Importance Analysis\n",
    "\n",
    "**What is Feature Importance?**\n",
    "- Measures how much each feature contributes to predictions\n",
    "- Higher importance = more influential\n",
    "- Helps understand what drives sales\n",
    "\n",
    "**How to Interpret:**\n",
    "\n",
    "**Top Features Likely Include:**\n",
    "1. **Lag features** (sales_lag_1, sales_lag_7)\n",
    "   - Past sales are strong predictors\n",
    "   - Lag_1 often most important\n",
    "\n",
    "2. **Rolling means** (sales_rolling_mean_7)\n",
    "   - Recent trend matters\n",
    "   - Smoothed signal useful\n",
    "\n",
    "3. **Day of week**\n",
    "   - Weekly seasonality strong\n",
    "   - Weekends vs weekdays\n",
    "\n",
    "4. **Month** (or month_sin/cos)\n",
    "   - Yearly seasonality\n",
    "   - Holiday seasons\n",
    "\n",
    "**Surprising Low Importance:**\n",
    "- If day-of-month has low importance: Good! It shouldn't matter much\n",
    "- If lag_1 has low importance: Concerning - may indicate data quality issues\n",
    "\n",
    "---\n",
    "\n",
    "**Visualization:**\n",
    "\n",
    "Horizontal bar chart:\n",
    "- Top 10-20 features\n",
    "- Sorted by importance\n",
    "- Easy to see what matters\n",
    "\n",
    "**Business Insights:**\n",
    "- High importance for lag_7 → Weekly patterns strong\n",
    "  - **Action:** Plan weekly promotions consistently\n",
    "  \n",
    "- High importance for day_of_week → Different staffing needed\n",
    "  - **Action:** Adjust schedules by day\n",
    "  \n",
    "- High importance for month → Seasonal trends\n",
    "  - **Action:** Adjust inventory seasonally\n",
    "\n",
    "---\n",
    "\n",
    "**Feature Selection:**\n",
    "\n",
    "**If you have many low-importance features:**\n",
    "- Consider removing them\n",
    "- Simplifies model\n",
    "- Faster training\n",
    "- Sometimes improves performance (reduces noise)\n",
    "\n",
    "**Threshold approach:**\n",
    "- Keep features with importance > 0.01\n",
    "- Or top 80% cumulative importance\n",
    "- Retrain and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Business Insights and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Translating Model Performance to Business Value\n",
    "\n",
    "**Connect Metrics to Business Impact:**\n",
    "\n",
    "**Example:**\n",
    "- MAE = 50 items per day\n",
    "- Average daily sales = 800 items\n",
    "- Prediction accuracy = 1 - (50/800) = 93.75%\n",
    "\n",
    "**Business Translation:**\n",
    "- \"Our forecasts are 94% accurate on average\"\n",
    "- \"We can predict daily sales within ±50 items\"\n",
    "- \"This allows 90% reduction in inventory waste\"\n",
    "\n",
    "**Quantify Value:**\n",
    "- Cost of overstocking: waste, storage\n",
    "- Cost of understocking: lost sales, customer dissatisfaction\n",
    "- Forecasting reduces both!\n",
    "\n",
    "**Example Calculation:**\n",
    "```\n",
    "Without forecasting:\n",
    "- Average inventory error: 100 items/day\n",
    "- Waste cost: $500/day\n",
    "\n",
    "With forecasting:\n",
    "- Average inventory error: 50 items/day\n",
    "- Waste cost: $250/day\n",
    "- Savings: $250/day × 365 = $91,250/year\n",
    "```\n",
    "\n",
    "**ROI Story:**\n",
    "- Implementation cost: X\n",
    "- Annual savings: Y\n",
    "- Payback period: X/Y months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Actionable Recommendations\n",
    "\n",
    "**1. Inventory Management**\n",
    "\n",
    "**Current Problem:**\n",
    "- Ordering same amount every day\n",
    "- Leads to waste on slow days\n",
    "- Stockouts on busy days\n",
    "\n",
    "**Recommendation:**\n",
    "- Use daily forecasts to adjust orders\n",
    "- Add safety stock = 1.5 × MAE\n",
    "- Different orders for weekdays vs weekends\n",
    "\n",
    "**Implementation:**\n",
    "- Run model daily to get next-day forecast\n",
    "- Automated ordering system\n",
    "- Alert if forecast > threshold\n",
    "\n",
    "**Expected Impact:**\n",
    "- 20-30% reduction in waste\n",
    "- 15-20% reduction in stockouts\n",
    "\n",
    "---\n",
    "\n",
    "**2. Staffing Optimization**\n",
    "\n",
    "**Insights from Analysis:**\n",
    "- Weekends 30% busier than weekdays\n",
    "- Month-end 15% higher sales\n",
    "- Predictable weekly patterns\n",
    "\n",
    "**Recommendations:**\n",
    "- Schedule 30% more staff on Fridays-Sundays\n",
    "- Add part-time staff for peak days\n",
    "- Reduce staffing on slowest days (e.g., Tuesday)\n",
    "\n",
    "**Implementation:**\n",
    "- Use 7-day forecast for next week's schedule\n",
    "- Build shift templates based on day-of-week patterns\n",
    "- Flexibility for predicted unusual days\n",
    "\n",
    "**Expected Impact:**\n",
    "- Better customer service (reduced wait times)\n",
    "- Lower labor costs (right-sized staffing)\n",
    "- Improved employee satisfaction (predictable schedules)\n",
    "\n",
    "---\n",
    "\n",
    "**3. Menu Optimization**\n",
    "\n",
    "**Findings:**\n",
    "- Top 20% of items drive 80% of revenue\n",
    "- Some items never sell (always 0)\n",
    "- High-price items have inconsistent sales\n",
    "\n",
    "**Recommendations:**\n",
    "- **Promote top sellers:** Feature on menu, marketing\n",
    "- **Remove zero-sellers:** Free up kitchen capacity\n",
    "- **Analyze slow-movers:** \n",
    "  - Price too high?\n",
    "  - Poor placement on menu?\n",
    "  - Quality issues?\n",
    "- **Seasonal menu:** Align with sales patterns\n",
    "\n",
    "**Implementation:**\n",
    "- Quarterly menu review based on sales data\n",
    "- A/B test menu changes\n",
    "- Track impact on overall sales\n",
    "\n",
    "---\n",
    "\n",
    "**4. Marketing & Promotions**\n",
    "\n",
    "**Strategic Timing:**\n",
    "- Run promotions on predicted slow days\n",
    "- Boost naturally busy days with targeted offers\n",
    "- Seasonal campaigns aligned with forecasts\n",
    "\n",
    "**Example:**\n",
    "- Tuesday is slowest day\n",
    "- Recommendation: \"Tuesday Special - 20% off\"\n",
    "- Goal: Smooth demand across week\n",
    "\n",
    "**Targeted Promotions:**\n",
    "- Item-specific: Push slow-moving items\n",
    "- Time-based: Happy hour during slow periods\n",
    "- Location-specific: Focus on underperforming restaurants\n",
    "\n",
    "---\n",
    "\n",
    "**5. Financial Planning**\n",
    "\n",
    "**Revenue Forecasting:**\n",
    "- 30-day revenue forecast\n",
    "- Budget planning\n",
    "- Cash flow management\n",
    "\n",
    "**Scenario Analysis:**\n",
    "- Best case: +10% from forecast\n",
    "- Expected case: Forecast\n",
    "- Worst case: -10% from forecast\n",
    "- Plan for all scenarios\n",
    "\n",
    "**Investment Decisions:**\n",
    "- Expansion timing based on growth trends\n",
    "- Equipment purchases aligned with forecast volume\n",
    "- Data-driven business case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Model Limitations and Future Improvements\n",
    "\n",
    "**Current Limitations:**\n",
    "\n",
    "**1. Aggregate-Only Forecasting:**\n",
    "- Currently predicting total sales\n",
    "- Not item-level or restaurant-level\n",
    "- Less actionable for specific decisions\n",
    "\n",
    "**2. Missing External Factors:**\n",
    "- Weather (rain reduces sales?)\n",
    "- Holidays (Christmas, Thanksgiving)\n",
    "- Local events (concerts, sports games)\n",
    "- Competitor actions\n",
    "- Economic indicators\n",
    "\n",
    "**3. No Price Elasticity:**\n",
    "- Doesn't model impact of price changes\n",
    "- Can't predict effect of discounts\n",
    "- Assumes constant pricing\n",
    "\n",
    "**4. Short History:**\n",
    "- Only 3 years of data\n",
    "- Limited for capturing rare events\n",
    "- More data = better models\n",
    "\n",
    "---\n",
    "\n",
    "**Future Improvements:**\n",
    "\n",
    "**Phase 2: Item-Level Forecasting**\n",
    "- Build separate models for each item\n",
    "- Or hierarchical forecasting\n",
    "- More granular insights\n",
    "- Better inventory management\n",
    "\n",
    "**Phase 3: External Data Integration**\n",
    "- Weather data from API\n",
    "- Holiday calendar\n",
    "- Event calendar (local)\n",
    "- Foot traffic data\n",
    "\n",
    "**Phase 4: Advanced Models**\n",
    "- LSTM/RNN (deep learning for time series)\n",
    "- Prophet (Facebook's forecasting tool)\n",
    "- Ensemble of multiple models\n",
    "- Bayesian methods for uncertainty quantification\n",
    "\n",
    "**Phase 5: Real-Time System**\n",
    "- Automated daily retraining\n",
    "- Dashboard for stakeholders\n",
    "- API for integration with ordering system\n",
    "- Mobile app for managers\n",
    "- Alerting for anomalies\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Wins (Low Effort, High Impact):**\n",
    "\n",
    "1. **Add holiday indicators** (0/1 flag)\n",
    "   - Major holidays known in advance\n",
    "   - Easy to implement\n",
    "   - Likely significant impact\n",
    "\n",
    "2. **Restaurant-specific models**\n",
    "   - Filter data by restaurant\n",
    "   - Train separate models\n",
    "   - Captures location-specific patterns\n",
    "\n",
    "3. **Weekend/Weekday separate models**\n",
    "   - Different patterns\n",
    "   - Two simpler models may outperform one complex model\n",
    "\n",
    "4. **Automated reporting**\n",
    "   - Daily email with forecast\n",
    "   - Weekly performance review\n",
    "   - Builds trust in system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overall Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Golden Rules\n",
    "\n",
    "**1. Never Shuffle Time Series Data**\n",
    "- ALWAYS use temporal train/test split\n",
    "- Past predicts future, not vice versa\n",
    "- Violating this gives meaningless results\n",
    "\n",
    "**2. Be Careful with Leakage**\n",
    "- Don't use future information in features\n",
    "- Rolling windows must only use past data\n",
    "- Example bad practice: Using day-30 average when predicting day 15\n",
    "\n",
    "**3. Start Simple, Then Complexify**\n",
    "- Baseline → Random Forest → XGBoost → Deep Learning\n",
    "- Each step should improve performance\n",
    "- If not, previous model was sufficient\n",
    "\n",
    "**4. Validate on Realistic Time Periods**\n",
    "- Don't test on 1 week (could be unusual)\n",
    "- Use at least 1-3 months\n",
    "- Captures different patterns\n",
    "\n",
    "**5. Monitor Model Drift**\n",
    "- Models degrade over time\n",
    "- Business patterns change\n",
    "- Re-train regularly (monthly/quarterly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Organization\n",
    "\n",
    "**Recommended Structure:**\n",
    "\n",
    "```\n",
    "1. Imports and Setup\n",
    "2. Data Loading\n",
    "3. Data Cleaning\n",
    "4. Exploratory Data Analysis\n",
    "5. Feature Engineering\n",
    "6. Train/Test Split\n",
    "7. Baseline Model\n",
    "8. ML Models (Random Forest, XGBoost)\n",
    "9. Model Comparison\n",
    "10. Visualization and Interpretation\n",
    "11. Business Insights\n",
    "12. Conclusions\n",
    "```\n",
    "\n",
    "**Functions to Create:**\n",
    "- `create_time_features(df)` - Add temporal features\n",
    "- `create_lag_features(df, lags)` - Add lag features\n",
    "- `create_rolling_features(df, windows)` - Add rolling stats\n",
    "- `evaluate_model(y_true, y_pred)` - Calculate metrics\n",
    "- `plot_predictions(dates, actual, predicted)` - Visualization\n",
    "\n",
    "**Why Functions?**\n",
    "- Reusable code\n",
    "- Easier to test\n",
    "- Cleaner notebooks\n",
    "- Professional practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation and Communication\n",
    "\n",
    "**Throughout Your Notebook:**\n",
    "\n",
    "**Markdown Cells for:**\n",
    "- Section explanations\n",
    "- Interpretation of results\n",
    "- Business insights\n",
    "- Decisions made and why\n",
    "\n",
    "**Code Comments for:**\n",
    "- Complex logic\n",
    "- Non-obvious choices\n",
    "- Parameter selections\n",
    "\n",
    "**Visualizations Should:**\n",
    "- Have clear titles\n",
    "- Labeled axes with units\n",
    "- Legends when needed\n",
    "- Annotations for key points\n",
    "\n",
    "**Final Summary Should Include:**\n",
    "- Key findings from EDA\n",
    "- Model performance comparison\n",
    "- Best model and why\n",
    "- Actionable recommendations\n",
    "- Limitations and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Skills\n",
    "\n",
    "**You will learn:**\n",
    "- Time series data handling and preprocessing\n",
    "- Feature engineering for temporal data\n",
    "- Proper train/test splitting for time series\n",
    "- Multiple forecasting approaches (statistical and ML)\n",
    "- Model evaluation specific to time series\n",
    "- Visualization of temporal patterns\n",
    "- Interpretation of model predictions and errors\n",
    "\n",
    "**Key Concepts:**\n",
    "- Temporal dependency and autocorrelation\n",
    "- Seasonality (daily, weekly, monthly)\n",
    "- Trends and cycles\n",
    "- Lag effects\n",
    "- Moving averages and smoothing\n",
    "- Feature importance in time series context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Skills\n",
    "\n",
    "**You will demonstrate:**\n",
    "- Translating data patterns into business insights\n",
    "- Quantifying business value of models\n",
    "- Creating actionable recommendations\n",
    "- Communicating technical results to non-technical stakeholders\n",
    "- Understanding operational applications (inventory, staffing)\n",
    "- Recognizing model limitations and risks\n",
    "- Planning phased implementation\n",
    "\n",
    "**Real-World Applications:**\n",
    "- Inventory optimization\n",
    "- Workforce planning\n",
    "- Revenue forecasting\n",
    "- Marketing campaign timing\n",
    "- Financial budgeting\n",
    "- Strategic decision support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critical Thinking Questions\n",
    "\n",
    "**Throughout the project, ask yourself:**\n",
    "\n",
    "**Data Quality:**\n",
    "- Why are there so many zero sales records?\n",
    "- Are there any suspicious patterns or outliers?\n",
    "- How complete and accurate is the data?\n",
    "\n",
    "**Modeling:**\n",
    "- Why did I choose these lag periods?\n",
    "- Which features matter most and why?\n",
    "- Is my model overfitting or underfitting?\n",
    "- Could I be leaking future information?\n",
    "\n",
    "**Business:**\n",
    "- How would a restaurant actually use these forecasts?\n",
    "- What's the cost of being wrong?\n",
    "- Is the model improvement worth the implementation cost?\n",
    "- What could cause the model to fail in production?\n",
    "\n",
    "**Ethics and Risks:**\n",
    "- Could this lead to understaffing and poor service?\n",
    "- What if the model is wrong during a critical period?\n",
    "- How do we monitor and maintain model quality?\n",
    "- What's the fallback if the system fails?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Load and explore the data** - Understand what you're working with\n",
    "2. **Start with EDA** - Find patterns before modeling\n",
    "3. **Create basic features first** - Time-based features\n",
    "4. **Add lag and rolling features** - Capture temporal dependencies\n",
    "5. **Build baseline model** - Establish minimum performance\n",
    "6. **Try Random Forest** - Likely your best model\n",
    "7. **Experiment with XGBoost** - If you want optimal performance\n",
    "8. **Visualize extensively** - Understand model behavior\n",
    "9. **Extract business insights** - Make it actionable\n",
    "10. **Document everything** - Tell the complete story\n",
    "\n",
    "**Remember:**\n",
    "- Time series is different from regular ML - respect temporal order!\n",
    "- Feature engineering is critical for good performance\n",
    "- Interpretability matters - explain your model's decisions\n",
    "- Business value > Technical sophistication\n",
    "- Simple models that work > Complex models that don't\n",
    "\n",
    "**You're building a real forecasting system that could:**\n",
    "- Reduce food waste\n",
    "- Improve customer service\n",
    "- Optimize labor costs\n",
    "- Increase profitability\n",
    "\n",
    "That's impactful work! Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
